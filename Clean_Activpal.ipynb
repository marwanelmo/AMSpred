{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import traceback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "all_filesVU = []\n",
    "all_filesANT = []\n",
    "for i in [0, 1, 3, 5, 6]:\n",
    "    folder = f'T{i}'\n",
    "    try:\n",
    "        folder_path = f'Activpal/Excel bestanden VUmc/{folder}'\n",
    "        files_and_folders = os.listdir(folder_path)\n",
    "        files = [os.path.join(folder_path, f) for f in files_and_folders if os.path.isfile(os.path.join(folder_path, f))]\n",
    "        all_filesVU += files\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        folder_path = f'Activpal/Excel bestanden Antonius/{folder}'\n",
    "        files_and_folders = os.listdir(folder_path)\n",
    "        files = [os.path.join(folder_path, f) for f in files_and_folders if os.path.isfile(os.path.join(folder_path, f))]\n",
    "        all_filesANT += files\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "print(len(all_filesANT), len(all_filesVU))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def extract_patient_id(filename, prefix):\n",
    "    \"\"\"\n",
    "    Extracts the patient ID using a regular expression that matches a specified prefix followed by two or three digits.\n",
    "    Assumes this pattern is immediately followed by an underscore.\n",
    "    Parameters:\n",
    "        filename (str): The name of the file from which to extract the ID.\n",
    "        prefix (str): The prefix to look for before the numeric ID.\n",
    "    Returns:\n",
    "        int: The extracted patient ID.\n",
    "    Raises:\n",
    "        ValueError: If the patient ID pattern is not found in the filename.\n",
    "    \"\"\"\n",
    "    regex_pattern = rf'{re.escape(prefix)}(\\d{{2,3}})_'\n",
    "    match = re.search(regex_pattern, filename)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    else:\n",
    "        raise ValueError(f\"Patient ID not found in filename following the pattern {prefix}.\")\n",
    "\n",
    "def process_file(file, prefix):\n",
    "    \"\"\"\n",
    "    Reads an Excel file, extracts relevant columns, and appends additional info including a patient ID derived from the filename.\n",
    "    Parameters:\n",
    "        file (str): Path to the Excel file.\n",
    "        prefix (str): Prefix to use in ID extraction from the filename.\n",
    "    Returns:\n",
    "        DataFrame: The processed data with additional columns for patient ID and time extracted from filename.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_excel(file, skiprows=13).iloc[:, [3, 5, 6, 7, 8, 10, 12, 16, 22, 23]]\n",
    "        patid = extract_patient_id(file, prefix)\n",
    "        tijd = file.split('/')[2][:2]\n",
    "        df['patid'] = patid\n",
    "        df['Tijd'] = tijd\n",
    "        df['Locatie'] = prefix\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Main loop to process files\n",
    "dfs = []\n",
    "\n",
    "for file in all_filesVU:\n",
    "    df = process_file(file, 'VU')\n",
    "    if df is not None:\n",
    "        dfs.append(df)\n",
    "for file in all_filesANT:\n",
    "    df = process_file(file, 'ANT')\n",
    "    if df is not None:\n",
    "        dfs.append(df)\n",
    "\n",
    "# Concatenate all DataFrames into one big DataFrame\n",
    "df_AP = pd.concat(dfs, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_AP.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming df is your DataFrame containing the data\n",
    "df_AP = df_AP[df_AP['ValidDay'] == 1]\n",
    "\n",
    "# Group by Locatie, patid, and Tijd and calculate averages and counts\n",
    "grouped_data = df_AP.groupby(['Locatie', 'patid', 'Tijd']).agg({\n",
    "    'StepCount': 'mean',\n",
    "    'TotalRLMsTime(m)': 'mean',\n",
    "    'TotalSedentaryTime(m)': 'mean',\n",
    "    'ActivityScore(MET.h)': 'mean',\n",
    "    'NumSitToStands': 'mean',\n",
    "    'DayOfWeek': 'count'  # Count the number of observations\n",
    "}).rename(columns={'DayOfWeek': 'Observations'})\n",
    "\n",
    "grouped_data = grouped_data.reset_index()\n",
    "grouped_data\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming grouped_data is your DataFrame with columns 'Locatie' and 'patid'\n",
    "# For demonstration, let's create a sample DataFrame\n",
    "\n",
    "# Function to transform patid\n",
    "def transform_patid(patid):\n",
    "    if patid < 10:\n",
    "        return '0' + str(patid)\n",
    "    elif patid >= 100:\n",
    "        return str(patid)\n",
    "    else:\n",
    "        return '{:02d}'.format(patid)\n",
    "\n",
    "# Apply the function to patid\n",
    "grouped_data['patid'] = grouped_data['patid'].apply(transform_patid)\n",
    "\n",
    "# Creating the new column with the specified structure\n",
    "grouped_data['pat_identifier'] = 'pp_OPRAH_' + grouped_data['Locatie'] + '_' + grouped_data['patid']\n",
    "grouped_data\n",
    "\n",
    "tijd = ['T0', 'T1', 'T3', 'T5', 'T6']\n",
    "\n",
    "for t in tijd:\n",
    "    df = grouped_data[grouped_data['Tijd'] == t]\n",
    "    df.to_excel(f'export/Activpal_{t}.xlsx')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract unique 'patid' values for ANT and VU\n",
    "patids_ANT = grouped_data.loc['ANT'].index.get_level_values('patid').unique()\n",
    "patids_VU = grouped_data.loc['VU'].index.get_level_values('patid'). bv ()\n",
    "\n",
    "# Get unique values of 'Tijd' from df_AP\n",
    "unique_tijds = df_AP['Tijd'].unique()\n",
    "\n",
    "# Create MultiIndex for ANT DataFrame\n",
    "index_ANT = pd.MultiIndex.from_product([patids_ANT, unique_tijds], names=['patid', 'Tijd'])\n",
    "df_ANT = pd.DataFrame(index=index_ANT, columns=grouped_data.columns).fillna(0)\n",
    "df_ANT['Location'] = 'ANT'\n",
    "df_ANT.set_index('Location', append=True, inplace=True)\n",
    "\n",
    "# Create MultiIndex for VU DataFrame\n",
    "index_VU = pd.MultiIndex.from_product([patids_VU, unique_tijds], names=['patid', 'Tijd'])\n",
    "df_VU = pd.DataFrame(index=index_VU, columns=grouped_data.columns).fillna(0)\n",
    "df_VU['Location'] = 'VU'\n",
    "df_VU.set_index('Location', append=True, inplace=True)\n",
    "\n",
    "# Concatenate ANT and VU DataFrames\n",
    "empty_df = pd.concat([df_VU, df_ANT])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add values from grouped_data and empty_df together\n",
    "merged_df = empty_df.add(grouped_data, fill_value=0)\n",
    "\n",
    "merged_df.to_excel('text.xlsx')\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sum up the 'Observations' column for each combination of 'patid', 'Locatie', and 'Tijd'\n",
    "heatmap_data = grouped_data.groupby([ 'Locatie','patid', 'Tijd'])['Observations'].sum().unstack(fill_value=0)\n",
    "\n",
    "# Voeg een extra kolom toe die het aantal kolommen telt waarvan de waarde niet gelijk aan 0 is\n",
    "heatmap_data['AantalNietNul'] = [sum(1 for value in row if value != 0) for row in heatmap_data.values[:, :]]\n",
    "\n",
    "heatmap_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "aantal_compleet = np.sum(heatmap_data['AantalNietNul'] == 5)\n",
    "print(f'Er zijn {aantal_compleet} complete patienten')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter('export/exportAP.xlsx') as writer:\n",
    "    # Write grouped_data to the first sheet\n",
    "    grouped_data.to_excel(writer, sheet_name='Gemiddeldes per patient')\n",
    "\n",
    "    # Write heatmap_data to the second sheet\n",
    "    heatmap_data.to_excel(writer, sheet_name='Aantal observation per patient')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the total number of rows\n",
    "total_days = len(df_AP)\n",
    "\n",
    "# Calculate the number of valid days (where ValidDay == 1)\n",
    "valid_days = df_AP[df_AP['ValidDay'] == 1]['ValidDay'].count()\n",
    "\n",
    "# Calculate the ratio of valid days\n",
    "valid_days_ratio = valid_days / total_days\n",
    "\n",
    "print(\"Ratio of valid days:\", round(100*valid_days_ratio, 1), \"%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
