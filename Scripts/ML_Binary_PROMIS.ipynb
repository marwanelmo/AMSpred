{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import statsmodels.api as sm\n",
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the new voorspelers file with semicolon separator\n",
    "voorspellers_df = pd.read_csv('../Export/Voorspellers.csv', delimiter=';')\n",
    "\n",
    "# Load the uitkomstmaat data_clean_cleanset\n",
    "uitkomstmaat_df = pd.read_csv('../Export/uitkomstmaat.csv', delimiter=';')\n",
    "uitkomstmaat_vars = uitkomstmaat_df[[\"patientnummer\", \"T0\", \"T5\"]]\n",
    "\n",
    "ML_df = pd.merge(voorspellers_df, uitkomstmaat_vars, left_on='Participant Id', right_on='patientnummer', how='inner')\n",
    "ML_df.drop(columns=['Participant Id', 'patientnummer'], inplace=True)\n",
    "ML_df['T5_relative'] = ML_df['T5']/ML_df['T0']\n",
    "ML_df['T5_recovered'] = ML_df['T5_relative'] >= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of people below 0.9 and above 0.9\n",
    "below_count = ML_df[ML_df['T5_relative'] < 1].shape[0]\n",
    "above_count = ML_df[ML_df['T5_relative'] >= 1].shape[0]\n",
    "\n",
    "print(f\"Number of people with T5_relative below 1: {below_count}\")\n",
    "print(f\"Number of people with T5_relative 1 or above: {above_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Assume ML_df is your DataFrame\n",
    "# data_clean is data met Imputation\n",
    "# data is data zonder imputation\n",
    "data_clean = ML_df.copy()\n",
    "data = ML_df.copy()\n",
    "\n",
    "# Identify columns\n",
    "continuous_columns = [\n",
    "    'T0_age', 'T0_BMI', 'T0_BIA_VVM_kg', 'T0_BIA_vetmassa_kg', \n",
    "    'Time_pretreat_OK', 'OK_Duration_min', 'Length_of_stay', \n",
    "    'T0_30SCST', 'T0_fatigue', 'T0_protein_perc', 'T0_kcal_perc', \n",
    "    'T0_CT_SMI', 'T0_CT_SMRA', 't0_gses_totaal_score', \n",
    "    'T0_participation_ability', 'T0_participation_satisfaction', \n",
    "    't0_EQ_5D_5L_beschrijvend-systeem_score', 'T0_pain', 'T0'\n",
    "]\n",
    "\n",
    "categorical_columns = [\n",
    "    'T0_VVMI_per', 'Education', 'household', 'T0_Tumorsize', \n",
    "    'T0_diseaseburden_cat', 'T0_selfcare', 'T0_Locusofcontrol_cat',\n",
    "    'T0_socialsupport_cat', 'T0_coping_cat', 'AMEXO_8_day1', \n",
    "    'AMEXO_9_day2', 'AMEXO_10_day3', 'T0_sondevoeding', 'T0_protein_cat',\n",
    "    'T0_kcal_cat', 'T0_ASM_low', 'T0_anxiety_cat', 'T0_depression_cat'\n",
    "]\n",
    "\n",
    "# Remove rows with missing values in T5\n",
    "if 'T5_relative' in data_clean.columns:\n",
    "    data_clean = data_clean.dropna(subset=['T5_relative'])\n",
    "\n",
    "# Remove rows where T5 > 80\n",
    "if 'T5' in data_clean.columns:\n",
    "    data_clean = data_clean[data_clean['T5'] <= 80]\n",
    "\n",
    "# Initialize the SimpleImputer with median strategy for continuous variables\n",
    "median_imputer = SimpleImputer(strategy='median')\n",
    "\n",
    "# Apply median imputation excluding 'T5'\n",
    "existing_continuous_columns = [col for col in continuous_columns if col in data_clean.columns]\n",
    "if existing_continuous_columns:\n",
    "    data_clean[existing_continuous_columns] = median_imputer.fit_transform(data_clean[existing_continuous_columns])\n",
    "\n",
    "# Initialize the SimpleImputer with mode strategy for categorical variables\n",
    "mode_imputer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "# Apply mode imputation to categorical columns\n",
    "existing_categorical_columns = [col for col in categorical_columns if col in data_clean.columns]\n",
    "if existing_categorical_columns:\n",
    "    data_clean[existing_categorical_columns] = mode_imputer.fit_transform(data_clean[existing_categorical_columns])\n",
    "\n",
    "# Fill missing values for specific columns with 0\n",
    "for col in ['Complications_CCI', 'readmission_30days', 'Time_OK_posttreat']:\n",
    "    if col in data_clean.columns:\n",
    "        data_clean[col] = data_clean[col].fillna(0)\n",
    "\n",
    "# Verify no remaining missing values except for T5\n",
    "missing_values_final_check = data_clean.isnull().sum()\n",
    "data_clean\n",
    "\n",
    "# Output the missing values check\n",
    "missing_values_final_check.sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Controleer op NaN of oneindige waarden en verwijder deze uit de kolom T5\n",
    "t5_cleaned = data_clean['T5_relative'].replace([np.inf, -np.inf], np.nan).dropna()\n",
    "t5_cleaned.hist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Train / Test Split\n",
    "- Hier pak ik 4 modellen, Logistic Regression, Decision tree, XGBoost en Nul model (mode) en ik train deze modellen op de test en kijk naar de nauwkeurigheid op de test set. Dit is nog zonder parameter optimalisatie. Alle modellen. Inclusief de lasso regressie lijken het slechter te doen dan de null model.\n",
    "- Daarna heb ik een RFE benadering geprobeerd met dezelfde modellen\n",
    "- Daarna heb ik een forward feature selection gebprobeerd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, plot_confusion_matrix\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Assuming data_clean is already defined and clean\n",
    "\n",
    "# Select the features and target variable\n",
    "X = data_clean.drop(columns=['T5', 'T5_relative', 'T5_recovered'])\n",
    "y = data_clean['T5_recovered']\n",
    "\n",
    "# Maak een train/test split met 70% train en 30% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Functie om de metrics te berekenen\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    specificity = tn / (tn + fp)\n",
    "    return accuracy, precision, recall, specificity, f1\n",
    "\n",
    "# Initialize and train models\n",
    "# Logistic Regression\n",
    "log_reg = LogisticRegression(max_iter=10000)\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Decision Tree with max_leaf_nodes to reduce overfitting\n",
    "tree_model = DecisionTreeClassifier(random_state=42, max_leaf_nodes=5)\n",
    "tree_model.fit(X_train, y_train)\n",
    "\n",
    "# XGBoost\n",
    "xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Null Model\n",
    "class NullModel:\n",
    "    def fit(self, X, y):\n",
    "        self.mode = y.mode()[0]\n",
    "    def predict(self, X):\n",
    "        return np.full(len(X), self.mode)\n",
    "\n",
    "null_model = NullModel()\n",
    "null_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate models\n",
    "metrics = {\n",
    "    'Model': [],\n",
    "    'Dataset': [],\n",
    "    'Accuracy': [],\n",
    "    'Precision': [],\n",
    "    'Recall': [],\n",
    "    'Specificity': [],\n",
    "    'F1': []\n",
    "}\n",
    "\n",
    "# Logistic Regression\n",
    "y_test_pred = log_reg.predict(X_test)\n",
    "accuracy, precision, recall, specificity, f1 = calculate_metrics(y_test, y_test_pred)\n",
    "metrics['Model'].append('Logistic Regression')\n",
    "metrics['Dataset'].append('Test')\n",
    "metrics['Accuracy'].append(accuracy)\n",
    "metrics['Precision'].append(precision)\n",
    "metrics['Recall'].append(recall)\n",
    "metrics['Specificity'].append(specificity)\n",
    "metrics['F1'].append(f1)\n",
    "# Plot confusion matrix\n",
    "plot_confusion_matrix(log_reg, X_test, y_test, display_labels=['Not Recovered', 'Recovered'])\n",
    "plt.title('Confusion Matrix for Logistic Regression (Test)')\n",
    "plt.show()\n",
    "\n",
    "# Decision Tree\n",
    "y_test_pred = tree_model.predict(X_test)\n",
    "accuracy, precision, recall, specificity, f1 = calculate_metrics(y_test, y_test_pred)\n",
    "metrics['Model'].append('Decision Tree')\n",
    "metrics['Dataset'].append('Test')\n",
    "metrics['Accuracy'].append(accuracy)\n",
    "metrics['Precision'].append(precision)\n",
    "metrics['Recall'].append(recall)\n",
    "metrics['Specificity'].append(specificity)\n",
    "metrics['F1'].append(f1)\n",
    "# Plot confusion matrix\n",
    "plot_confusion_matrix(tree_model, X_test, y_test, display_labels=['Not Recovered', 'Recovered'])\n",
    "plt.title('Confusion Matrix for Decision Tree (Test)')\n",
    "plt.show()\n",
    "\n",
    "# XGBoost\n",
    "y_test_pred = xgb_model.predict(X_test)\n",
    "accuracy, precision, recall, specificity, f1 = calculate_metrics(y_test, y_test_pred)\n",
    "metrics['Model'].append('XGBoost')\n",
    "metrics['Dataset'].append('Test')\n",
    "metrics['Accuracy'].append(accuracy)\n",
    "metrics['Precision'].append(precision)\n",
    "metrics['Recall'].append(recall)\n",
    "metrics['Specificity'].append(specificity)\n",
    "metrics['F1'].append(f1)\n",
    "# Plot confusion matrix\n",
    "plot_confusion_matrix(xgb_model, X_test, y_test, display_labels=['Not Recovered', 'Recovered'])\n",
    "plt.title('Confusion Matrix for XGBoost (Test)')\n",
    "plt.show()\n",
    "\n",
    "# Null Model\n",
    "y_test_pred = null_model.predict(X_test)\n",
    "accuracy, precision, recall, specificity, f1 = calculate_metrics(y_test, y_test_pred)\n",
    "metrics['Model'].append('Null Model')\n",
    "metrics['Dataset'].append('Test')\n",
    "metrics['Accuracy'].append(accuracy)\n",
    "metrics['Precision'].append(precision)\n",
    "metrics['Recall'].append(recall)\n",
    "metrics['Specificity'].append(specificity)\n",
    "metrics['F1'].append(f1)\n",
    "# Plot confusion matrix\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "fig, ax = plt.subplots()\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax)\n",
    "ax.set(xlabel='Predicted', ylabel='True', title='Confusion Matrix for Null Model (Test)')\n",
    "ax.set_xticklabels(['Not Recovered', 'Recovered'])\n",
    "ax.set_yticklabels(['Not Recovered', 'Recovered'])\n",
    "plt.show()\n",
    "\n",
    "# Convert metrics to DataFrame\n",
    "metrics_df = pd.DataFrame(metrics)\n",
    "\n",
    "# Display the results\n",
    "print(metrics_df)\n",
    "\n",
    "# Plot the Decision Tree\n",
    "plt.figure(figsize=(20,10))\n",
    "plot_tree(tree_model, feature_names=X.columns, class_names=['Not Recovered', 'Recovered'], filled=True, rounded=True, fontsize=10)\n",
    "plt.title('Decision Tree')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, plot_confusion_matrix\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import shap\n",
    "\n",
    "# Assuming data_clean is already defined and clean\n",
    "\n",
    "# Select the features and target variable\n",
    "X = data_clean.drop(columns=['T5', 'T5_relative', 'T5_recovered'])\n",
    "y = data_clean['T5_recovered']\n",
    "\n",
    "# Make a train/test split with 70% train and 30% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Function to calculate metrics\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    specificity = tn / (tn + fp)\n",
    "    return accuracy, precision, recall, specificity, f1\n",
    "\n",
    "# Initialize and train models\n",
    "# Logistic Regression\n",
    "log_reg = LogisticRegression(max_iter=10000)\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Decision Tree with max_leaf_nodes to reduce overfitting\n",
    "tree_model = DecisionTreeClassifier(random_state=42, max_leaf_nodes=5)\n",
    "tree_model.fit(X_train, y_train)\n",
    "\n",
    "# XGBoost\n",
    "xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Null Model\n",
    "class NullModel:\n",
    "    def fit(self, X, y):\n",
    "        self.mode = y.mode()[0]\n",
    "    def predict(self, X):\n",
    "        return np.full(len(X), self.mode)\n",
    "\n",
    "null_model = NullModel()\n",
    "null_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate models\n",
    "metrics = {\n",
    "    'Model': [],\n",
    "    'Dataset': [],\n",
    "    'Accuracy': [],\n",
    "    'Precision': [],\n",
    "    'Recall': [],\n",
    "    'Specificity': [],\n",
    "    'F1': []\n",
    "}\n",
    "\n",
    "# Logistic Regression\n",
    "y_test_pred = log_reg.predict(X_test)\n",
    "accuracy, precision, recall, specificity, f1 = calculate_metrics(y_test, y_test_pred)\n",
    "metrics['Model'].append('Logistic Regression')\n",
    "metrics['Dataset'].append('Test')\n",
    "metrics['Accuracy'].append(accuracy)\n",
    "metrics['Precision'].append(precision)\n",
    "metrics['Recall'].append(recall)\n",
    "metrics['Specificity'].append(specificity)\n",
    "metrics['F1'].append(f1)\n",
    "# Plot confusion matrix\n",
    "plot_confusion_matrix(log_reg, X_test, y_test, display_labels=['Not Recovered', 'Recovered'])\n",
    "plt.title('Confusion Matrix for Logistic Regression (Test)')\n",
    "plt.show()\n",
    "\n",
    "# Display feature importance and direction for Logistic Regression\n",
    "coefficients = pd.DataFrame({'Feature': X.columns, 'Coefficient': log_reg.coef_[0]})\n",
    "coefficients['Direction'] = coefficients['Coefficient'].apply(lambda x: 'Positive' if x > 0 else 'Negative')\n",
    "coefficients = coefficients.sort_values(by='Coefficient', key=abs, ascending=False)\n",
    "print(coefficients)\n",
    "\n",
    "# Plot feature importance for Logistic Regression\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.barplot(data=coefficients, x='Coefficient', y='Feature', hue='Direction', dodge=False)\n",
    "plt.title('Feature Importance and Direction for Logistic Regression')\n",
    "plt.show()\n",
    "\n",
    "# Decision Tree\n",
    "y_test_pred = tree_model.predict(X_test)\n",
    "accuracy, precision, recall, specificity, f1 = calculate_metrics(y_test, y_test_pred)\n",
    "metrics['Model'].append('Decision Tree')\n",
    "metrics['Dataset'].append('Test')\n",
    "metrics['Accuracy'].append(accuracy)\n",
    "metrics['Precision'].append(precision)\n",
    "metrics['Recall'].append(recall)\n",
    "metrics['Specificity'].append(specificity)\n",
    "metrics['F1'].append(f1)\n",
    "# Plot confusion matrix\n",
    "plot_confusion_matrix(tree_model, X_test, y_test, display_labels=['Not Recovered', 'Recovered'])\n",
    "plt.title('Confusion Matrix for Decision Tree (Test)')\n",
    "plt.show()\n",
    "\n",
    "# XGBoost\n",
    "y_test_pred = xgb_model.predict(X_test)\n",
    "accuracy, precision, recall, specificity, f1 = calculate_metrics(y_test, y_test_pred)\n",
    "metrics['Model'].append('XGBoost')\n",
    "metrics['Dataset'].append('Test')\n",
    "metrics['Accuracy'].append(accuracy)\n",
    "metrics['Precision'].append(precision)\n",
    "metrics['Recall'].append(recall)\n",
    "metrics['Specificity'].append(specificity)\n",
    "metrics['F1'].append(f1)\n",
    "# Plot confusion matrix\n",
    "plot_confusion_matrix(xgb_model, X_test, y_test, display_labels=['Not Recovered', 'Recovered'])\n",
    "plt.title('Confusion Matrix for XGBoost (Test)')\n",
    "plt.show()\n",
    "\n",
    "# Display feature importance for XGBoost\n",
    "xgb_importances = pd.DataFrame({'Feature': X.columns, 'Importance': xgb_model.feature_importances_})\n",
    "xgb_importances = xgb_importances.sort_values(by='Importance', ascending=False)\n",
    "print(xgb_importances)\n",
    "\n",
    "# Plot feature importance for XGBoost\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.barplot(data=xgb_importances, x='Importance', y='Feature')\n",
    "plt.title('Feature Importance for XGBoost')\n",
    "plt.show()\n",
    "\n",
    "# SHAP values for XGBoost to determine direction\n",
    "explainer = shap.TreeExplainer(xgb_model)\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "# Summary plot for SHAP values\n",
    "shap.summary_plot(shap_values, X_test, feature_names=X.columns, plot_type='bar')\n",
    "shap.summary_plot(shap_values, X_test, feature_names=X.columns)\n",
    "\n",
    "# Null Model\n",
    "y_test_pred = null_model.predict(X_test)\n",
    "accuracy, precision, recall, specificity, f1 = calculate_metrics(y_test, y_test_pred)\n",
    "metrics['Model'].append('Null Model')\n",
    "metrics['Dataset'].append('Test')\n",
    "metrics['Accuracy'].append(accuracy)\n",
    "metrics['Precision'].append(precision)\n",
    "metrics['Recall'].append(recall)\n",
    "metrics['Specificity'].append(specificity)\n",
    "metrics['F1'].append(f1)\n",
    "# Plot confusion matrix\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "fig, ax = plt.subplots()\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax)\n",
    "ax.set(xlabel='Predicted', ylabel='True', title='Confusion Matrix for Null Model (Test)')\n",
    "ax.set_xticklabels(['Not Recovered', 'Recovered'])\n",
    "ax.set_yticklabels(['Not Recovered', 'Recovered'])\n",
    "plt.show()\n",
    "\n",
    "# Convert metrics to DataFrame\n",
    "metrics_df = pd.DataFrame(metrics)\n",
    "\n",
    "# Display the results\n",
    "print(metrics_df)\n",
    "\n",
    "# Plot the Decision Tree\n",
    "plt.figure(figsize=(20,10))\n",
    "plot_tree(tree_model, feature_names=X.columns, class_names=['Not Recovered', 'Recovered'], filled=True, rounded=True, fontsize=10)\n",
    "plt.title('Decision Tree')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, plot_confusion_matrix\n",
    "from sklearn.feature_selection import RFE\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Assuming data_clean is already defined and clean\n",
    "\n",
    "# Select the features and target variable\n",
    "X = data_clean.drop(columns=['T5', 'T5_relative', 'T5_recovered'])\n",
    "y = data_clean['T5_recovered']\n",
    "\n",
    "# Maak een train/test split met 70% train en 30% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Recursive Feature Elimination (RFE) with Logistic Regression\n",
    "log_reg = LogisticRegression(max_iter=10000)\n",
    "rfe = RFE(log_reg, n_features_to_select=10)\n",
    "X_train_rfe = rfe.fit_transform(X_train, y_train)\n",
    "X_test_rfe = rfe.transform(X_test)\n",
    "\n",
    "# Functie om de metrics te berekenen\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    specificity = tn / (tn + fp)\n",
    "    return accuracy, precision, recall, specificity, f1\n",
    "\n",
    "# Initialize and train models using the reduced feature set\n",
    "# Logistic Regression\n",
    "log_reg.fit(X_train_rfe, y_train)\n",
    "\n",
    "# Decision Tree with max_leaf_nodes to reduce overfitting\n",
    "tree_model = DecisionTreeClassifier(random_state=42, max_leaf_nodes=5)\n",
    "tree_model.fit(X_train_rfe, y_train)\n",
    "\n",
    "# XGBoost\n",
    "xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "xgb_model.fit(X_train_rfe, y_train)\n",
    "\n",
    "# Null Model\n",
    "class NullModel:\n",
    "    def fit(self, X, y):\n",
    "        self.mode = y.mode()[0]\n",
    "    def predict(self, X):\n",
    "        return np.full(len(X), self.mode)\n",
    "\n",
    "null_model = NullModel()\n",
    "null_model.fit(X_train_rfe, y_train)\n",
    "\n",
    "# Evaluate models\n",
    "metrics = {\n",
    "    'Model': [],\n",
    "    'Dataset': [],\n",
    "    'Accuracy': [],\n",
    "    'Precision': [],\n",
    "    'Recall': [],\n",
    "    'Specificity': [],\n",
    "    'F1': []\n",
    "}\n",
    "\n",
    "# Logistic Regression\n",
    "y_test_pred = log_reg.predict(X_test_rfe)\n",
    "accuracy, precision, recall, specificity, f1 = calculate_metrics(y_test, y_test_pred)\n",
    "metrics['Model'].append('Logistic Regression')\n",
    "metrics['Dataset'].append('Test')\n",
    "metrics['Accuracy'].append(accuracy)\n",
    "metrics['Precision'].append(precision)\n",
    "metrics['Recall'].append(recall)\n",
    "metrics['Specificity'].append(specificity)\n",
    "metrics['F1'].append(f1)\n",
    "# Plot confusion matrix\n",
    "#plot_confusion_matrix(log_reg, X_test_rfe, y_test, display_labels=['Not Recovered', 'Recovered'])\n",
    "plt.title('Confusion Matrix for Logistic Regression (Test)')\n",
    "plt.show()\n",
    "\n",
    "# Decision Tree\n",
    "y_test_pred = tree_model.predict(X_test_rfe)\n",
    "accuracy, precision, recall, specificity, f1 = calculate_metrics(y_test, y_test_pred)\n",
    "metrics['Model'].append('Decision Tree')\n",
    "metrics['Dataset'].append('Test')\n",
    "metrics['Accuracy'].append(accuracy)\n",
    "metrics['Precision'].append(precision)\n",
    "metrics['Recall'].append(recall)\n",
    "metrics['Specificity'].append(specificity)\n",
    "metrics['F1'].append(f1)\n",
    "# Plot confusion matrix\n",
    "#plot_confusion_matrix(tree_model, X_test_rfe, y_test, display_labels=['Not Recovered', 'Recovered'])\n",
    "plt.title('Confusion Matrix for Decision Tree (Test)')\n",
    "plt.show()\n",
    "\n",
    "# XGBoost\n",
    "y_test_pred = xgb_model.predict(X_test_rfe)\n",
    "accuracy, precision, recall, specificity, f1 = calculate_metrics(y_test, y_test_pred)\n",
    "metrics['Model'].append('XGBoost')\n",
    "metrics['Dataset'].append('Test')\n",
    "metrics['Accuracy'].append(accuracy)\n",
    "metrics['Precision'].append(precision)\n",
    "metrics['Recall'].append(recall)\n",
    "metrics['Specificity'].append(specificity)\n",
    "metrics['F1'].append(f1)\n",
    "# Plot confusion matrix\n",
    "#plot_confusion_matrix(xgb_model, X_test_rfe, y_test, display_labels=['Not Recovered', 'Recovered'])\n",
    "plt.title('Confusion Matrix for XGBoost (Test)')\n",
    "plt.show()\n",
    "\n",
    "# Null Model\n",
    "y_test_pred = null_model.predict(X_test_rfe)\n",
    "accuracy, precision, recall, specificity, f1 = calculate_metrics(y_test, y_test_pred)\n",
    "metrics['Model'].append('Null Model')\n",
    "metrics['Dataset'].append('Test')\n",
    "metrics['Accuracy'].append(accuracy)\n",
    "metrics['Precision'].append(precision)\n",
    "metrics['Recall'].append(recall)\n",
    "metrics['Specificity'].append(specificity)\n",
    "metrics['F1'].append(f1)\n",
    "# Plot confusion matrix\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "fig, ax = plt.subplots()\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax)\n",
    "ax.set(xlabel='Predicted', ylabel='True', title='Confusion Matrix for Null Model (Test)')\n",
    "ax.set_xticklabels(['Not Recovered', 'Recovered'])\n",
    "ax.set_yticklabels(['Not Recovered', 'Recovered'])\n",
    "plt.show()\n",
    "\n",
    "# Convert metrics to DataFrame\n",
    "metrics_df = pd.DataFrame(metrics)\n",
    "\n",
    "# Display the results\n",
    "print(metrics_df)\n",
    "\n",
    "# Plot the Decision Tree\n",
    "plt.figure(figsize=(20,10))\n",
    "plot_tree(tree_model, feature_names=X.columns[rfe.get_support()], class_names=['Not Recovered', 'Recovered'], filled=True, rounded=True, fontsize=10)\n",
    "plt.title('Decision Tree')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, plot_confusion_matrix\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Assuming data_clean is already defined and clean\n",
    "\n",
    "# Select the features and target variable\n",
    "X = data_clean.drop(columns=['T5', 'T5_relative', 'T5_recovered'])\n",
    "y = data_clean['T5_recovered']\n",
    "\n",
    "# Maak een train/test split met 70% train en 30% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Functie om de metrics te berekenen\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    specificity = tn / (tn + fp)\n",
    "    return accuracy, precision, recall, specificity, f1\n",
    "\n",
    "# Forward feature selection function\n",
    "def forward_feature_selection(model, X_train, y_train, X_test, y_test):\n",
    "    initial_features = []\n",
    "    best_features = []\n",
    "    best_score = 0\n",
    "    current_score = 0\n",
    "\n",
    "    while True:\n",
    "        scores = []\n",
    "        for feature in X_train.columns:\n",
    "            if feature in initial_features:\n",
    "                continue\n",
    "            selected_features = initial_features + [feature]\n",
    "            model.fit(X_train[selected_features], y_train)\n",
    "            y_pred = model.predict(X_test[selected_features])\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            scores.append((accuracy, feature))\n",
    "\n",
    "        scores.sort(reverse=True)\n",
    "        current_score, best_feature = scores[0]\n",
    "\n",
    "        if current_score > best_score:\n",
    "            best_score = current_score\n",
    "            best_features.append(best_feature)\n",
    "            initial_features.append(best_feature)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return best_features\n",
    "\n",
    "# Logistic Regression\n",
    "log_reg = LogisticRegression(max_iter=10000)\n",
    "best_features_log_reg = forward_feature_selection(log_reg, X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Decision Tree\n",
    "tree_model = DecisionTreeClassifier(random_state=42, max_leaf_nodes=5)\n",
    "best_features_tree = forward_feature_selection(tree_model, X_train, y_train, X_test, y_test)\n",
    "\n",
    "# XGBoost\n",
    "xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "best_features_xgb = forward_feature_selection(xgb_model, X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Null Model\n",
    "class NullModel:\n",
    "    def fit(self, X, y):\n",
    "        self.mode = y.mode()[0]\n",
    "    def predict(self, X):\n",
    "        return np.full(len(X), self.mode)\n",
    "\n",
    "null_model = NullModel()\n",
    "null_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate models\n",
    "metrics = {\n",
    "    'Model': [],\n",
    "    'Dataset': [],\n",
    "    'Accuracy': [],\n",
    "    'Precision': [],\n",
    "    'Recall': [],\n",
    "    'Specificity': [],\n",
    "    'F1': []\n",
    "}\n",
    "\n",
    "# Logistic Regression\n",
    "log_reg.fit(X_train[best_features_log_reg], y_train)\n",
    "y_test_pred = log_reg.predict(X_test[best_features_log_reg])\n",
    "accuracy, precision, recall, specificity, f1 = calculate_metrics(y_test, y_test_pred)\n",
    "metrics['Model'].append('Logistic Regression')\n",
    "metrics['Dataset'].append('Test')\n",
    "metrics['Accuracy'].append(accuracy)\n",
    "metrics['Precision'].append(precision)\n",
    "metrics['Recall'].append(recall)\n",
    "metrics['Specificity'].append(specificity)\n",
    "metrics['F1'].append(f1)\n",
    "# Plot confusion matrix\n",
    "plot_confusion_matrix(log_reg, X_test[best_features_log_reg], y_test, display_labels=['Not Recovered', 'Recovered'])\n",
    "plt.title('Confusion Matrix for Logistic Regression (Test)')\n",
    "plt.show()\n",
    "\n",
    "# Decision Tree\n",
    "tree_model.fit(X_train[best_features_tree], y_train)\n",
    "y_test_pred = tree_model.predict(X_test[best_features_tree])\n",
    "accuracy, precision, recall, specificity, f1 = calculate_metrics(y_test, y_test_pred)\n",
    "metrics['Model'].append('Decision Tree')\n",
    "metrics['Dataset'].append('Test')\n",
    "metrics['Accuracy'].append(accuracy)\n",
    "metrics['Precision'].append(precision)\n",
    "metrics['Recall'].append(recall)\n",
    "metrics['Specificity'].append(specificity)\n",
    "metrics['F1'].append(f1)\n",
    "# Plot confusion matrix\n",
    "plot_confusion_matrix(tree_model, X_test[best_features_tree], y_test, display_labels=['Not Recovered', 'Recovered'])\n",
    "plt.title('Confusion Matrix for Decision Tree (Test)')\n",
    "plt.show()\n",
    "\n",
    "# XGBoost\n",
    "xgb_model.fit(X_train[best_features_xgb], y_train)\n",
    "y_test_pred = xgb_model.predict(X_test[best_features_xgb])\n",
    "accuracy, precision, recall, specificity, f1 = calculate_metrics(y_test, y_test_pred)\n",
    "metrics['Model'].append('XGBoost')\n",
    "metrics['Dataset'].append('Test')\n",
    "metrics['Accuracy'].append(accuracy)\n",
    "metrics['Precision'].append(precision)\n",
    "metrics['Recall'].append(recall)\n",
    "metrics['Specificity'].append(specificity)\n",
    "metrics['F1'].append(f1)\n",
    "# Plot confusion matrix\n",
    "plot_confusion_matrix(xgb_model, X_test[best_features_xgb], y_test, display_labels=['Not Recovered', 'Recovered'])\n",
    "plt.title('Confusion Matrix for XGBoost (Test)')\n",
    "plt.show()\n",
    "\n",
    "# Null Model\n",
    "y_test_pred = null_model.predict(X_test)\n",
    "accuracy, precision, recall, specificity, f1 = calculate_metrics(y_test, y_test_pred)\n",
    "metrics['Model'].append('Null Model')\n",
    "metrics['Dataset'].append('Test')\n",
    "metrics['Accuracy'].append(accuracy)\n",
    "metrics['Precision'].append(precision)\n",
    "metrics['Recall'].append(recall)\n",
    "metrics['Specificity'].append(specificity)\n",
    "metrics['F1'].append(f1)\n",
    "# Plot confusion matrix\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "fig, ax = plt.subplots()\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax)\n",
    "ax.set(xlabel='Predicted', ylabel='True', title='Confusion Matrix for Null Model (Test)')\n",
    "ax.set_xticklabels(['Not Recovered', 'Recovered'])\n",
    "ax.set_yticklabels(['Not Recovered', 'Recovered'])\n",
    "plt.show()\n",
    "\n",
    "# Convert metrics to DataFrame\n",
    "metrics_df = pd.DataFrame(metrics)\n",
    "\n",
    "# Display the results\n",
    "print(metrics_df)\n",
    "\n",
    "# Plot the Decision Tree\n",
    "plt.figure(figsize=(20,10))\n",
    "plot_tree(tree_model, feature_names=best_features_tree, class_names=['Not Recovered', 'Recovered'], filled=True, rounded=True, fontsize=10)\n",
    "plt.title('Decision Tree')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-Fold Cross Validation - train/validation set\n",
    "- Dataset wordt gesplitst in trainings- en testsets.\n",
    "- Er wordt een 5-voudige cross-validatie uitgevoerd met hyperparameter tuning voor zowel Lasso Regression als XGBoost Regression om de beste modelconfiguratie te vinden.\n",
    "- Het beste model wordt opnieuw getraind op de volledige trainingsset en geëvalueerd op de testset, waarbij de prestaties worden gemeten met MAE, RMSE en R².\n",
    "- Een null model, dat het gemiddelde van de trainingsset voorspelt, wordt gebruikt als benchmark om de prestaties van de regressiemodellen te vergelijken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming data_clean is already defined and clean\n",
    "\n",
    "# Select the features and target variable\n",
    "X = data_clean.drop(columns=['T5', 'T5_relative', 'T5_recovered'])\n",
    "y = data_clean['T5_recovered']\n",
    "\n",
    "# Maak een train/test split met 70% train en 30% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "# Logistic Regression\n",
    "log_reg = LogisticRegression(max_iter=10000)\n",
    "log_reg_params = {'C': [0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "# Decision Tree\n",
    "tree_model = DecisionTreeClassifier(random_state=42)\n",
    "tree_params = {'max_depth': [3, 5, 7, 10], 'max_leaf_nodes': [5, 10, 20, 30]}\n",
    "\n",
    "# XGBoost\n",
    "xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "xgb_params = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'subsample': [0.7, 0.8, 0.9],\n",
    "    'colsample_bytree': [0.7, 0.8, 0.9]\n",
    "}\n",
    "\n",
    "# KFold Cross-Validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform GridSearchCV\n",
    "log_reg_cv = GridSearchCV(log_reg, log_reg_params, cv=kf, scoring='accuracy')\n",
    "log_reg_cv.fit(X_train, y_train)\n",
    "\n",
    "tree_cv = GridSearchCV(tree_model, tree_params, cv=kf, scoring='accuracy')\n",
    "tree_cv.fit(X_train, y_train)\n",
    "\n",
    "xgb_cv = GridSearchCV(xgb_model, xgb_params, cv=kf, scoring='accuracy')\n",
    "xgb_cv.fit(X_train, y_train)\n",
    "\n",
    "# Best estimators\n",
    "best_log_reg = log_reg_cv.best_estimator_\n",
    "best_tree = tree_cv.best_estimator_\n",
    "best_xgb = xgb_cv.best_estimator_\n",
    "\n",
    "\n",
    "# Functie om de metrics te berekenen\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    specificity = tn / (tn + fp)\n",
    "    return accuracy, precision, recall, specificity, f1\n",
    "\n",
    "# Train the best models on the full training set\n",
    "best_log_reg.fit(X_train, y_train)\n",
    "best_tree.fit(X_train, y_train)\n",
    "best_xgb.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate models\n",
    "metrics = {\n",
    "    'Model': [],\n",
    "    'Dataset': [],\n",
    "    'Accuracy': [],\n",
    "    'Precision': [],\n",
    "    'Recall': [],\n",
    "    'Specificity': [],\n",
    "    'F1': []\n",
    "}\n",
    "\n",
    "# Logistic Regression\n",
    "y_test_pred = best_log_reg.predict(X_test)\n",
    "accuracy, precision, recall, specificity, f1 = calculate_metrics(y_test, y_test_pred)\n",
    "metrics['Model'].append('Logistic Regression')\n",
    "metrics['Dataset'].append('Test')\n",
    "metrics['Accuracy'].append(accuracy)\n",
    "metrics['Precision'].append(precision)\n",
    "metrics['Recall'].append(recall)\n",
    "metrics['Specificity'].append(specificity)\n",
    "metrics['F1'].append(f1)\n",
    "# Plot confusion matrix\n",
    "plot_confusion_matrix(best_log_reg, X_test, y_test, display_labels=['Not Recovered', 'Recovered'])\n",
    "plt.title('Confusion Matrix for Logistic Regression (Test)')\n",
    "plt.show()\n",
    "\n",
    "# Decision Tree\n",
    "y_test_pred = best_tree.predict(X_test)\n",
    "accuracy, precision, recall, specificity, f1 = calculate_metrics(y_test, y_test_pred)\n",
    "metrics['Model'].append('Decision Tree')\n",
    "metrics['Dataset'].append('Test')\n",
    "metrics['Accuracy'].append(accuracy)\n",
    "metrics['Precision'].append(precision)\n",
    "metrics['Recall'].append(recall)\n",
    "metrics['Specificity'].append(specificity)\n",
    "metrics['F1'].append(f1)\n",
    "# Plot confusion matrix\n",
    "plot_confusion_matrix(best_tree, X_test, y_test, display_labels=['Not Recovered', 'Recovered'])\n",
    "plt.title('Confusion Matrix for Decision Tree (Test)')\n",
    "plt.show()\n",
    "\n",
    "# XGBoost\n",
    "y_test_pred = best_xgb.predict(X_test)\n",
    "accuracy, precision, recall, specificity, f1 = calculate_metrics(y_test, y_test_pred)\n",
    "metrics['Model'].append('XGBoost')\n",
    "metrics['Dataset'].append('Test')\n",
    "metrics['Accuracy'].append(accuracy)\n",
    "metrics['Precision'].append(precision)\n",
    "metrics['Recall'].append(recall)\n",
    "metrics['Specificity'].append(specificity)\n",
    "metrics['F1'].append(f1)\n",
    "# Plot confusion matrix\n",
    "plot_confusion_matrix(best_xgb, X_test, y_test, display_labels=['Not Recovered', 'Recovered'])\n",
    "plt.title('Confusion Matrix for XGBoost (Test)')\n",
    "plt.show()\n",
    "\n",
    "# Null Model\n",
    "class NullModel:\n",
    "    def fit(self, X, y):\n",
    "        self.mode = y.mode()[0]\n",
    "    def predict(self, X):\n",
    "        return np.full(len(X), self.mode)\n",
    "\n",
    "null_model = NullModel()\n",
    "null_model.fit(X_train, y_train)\n",
    "\n",
    "# Null Model Evaluation\n",
    "y_test_pred = null_model.predict(X_test)\n",
    "accuracy, precision, recall, specificity, f1 = calculate_metrics(y_test, y_test_pred)\n",
    "metrics['Model'].append('Null Model')\n",
    "metrics['Dataset'].append('Test')\n",
    "metrics['Accuracy'].append(accuracy)\n",
    "metrics['Precision'].append(precision)\n",
    "metrics['Recall'].append(recall)\n",
    "metrics['Specificity'].append(specificity)\n",
    "metrics['F1'].append(f1)\n",
    "# Plot confusion matrix\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "fig, ax = plt.subplots()\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax)\n",
    "ax.set(xlabel='Predicted', ylabel='True', title='Confusion Matrix for Null Model (Test)')\n",
    "ax.set_xticklabels(['Not Recovered', 'Recovered'])\n",
    "ax.set_yticklabels(['Not Recovered', 'Recovered'])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Convert metrics to DataFrame\n",
    "metrics_df = pd.DataFrame(metrics)\n",
    "\n",
    "# Display the results\n",
    "print(metrics_df)\n",
    "\n",
    "# Plot the Decision Tree\n",
    "plt.figure(figsize=(20,10))\n",
    "plot_tree(best_tree, feature_names=X.columns, class_names=['Not Recovered', 'Recovered'], filled=True, rounded=True, fontsize=10)\n",
    "plt.title('Decision Tree')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, plot_confusion_matrix\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Assuming data_clean is already defined and clean\n",
    "\n",
    "# Select the features and target variable\n",
    "X = data_clean.drop(columns=['T5', 'T5_relative', 'T5_recovered'])\n",
    "y = data_clean['T5_recovered']\n",
    "\n",
    "# Split the data into training, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Functie om de metrics te berekenen\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    specificity = tn / (tn + fp)\n",
    "    return accuracy, precision, recall, specificity, f1\n",
    "\n",
    "# Forward feature selection function\n",
    "def forward_feature_selection(model, X_train, y_train, X_val, y_val):\n",
    "    initial_features = []\n",
    "    best_features = []\n",
    "    best_score = 0\n",
    "    current_score = 0\n",
    "\n",
    "    while True:\n",
    "        scores = []\n",
    "        for feature in X_train.columns:\n",
    "            if feature in initial_features:\n",
    "                continue\n",
    "            selected_features = initial_features + [feature]\n",
    "            model.fit(X_train[selected_features], y_train)\n",
    "            y_pred = model.predict(X_val[selected_features])\n",
    "            accuracy = accuracy_score(y_val, y_pred)\n",
    "            scores.append((accuracy, feature))\n",
    "\n",
    "        scores.sort(reverse=True)\n",
    "        current_score, best_feature = scores[0]\n",
    "\n",
    "        if current_score > best_score:\n",
    "            best_score = current_score\n",
    "            best_features.append(best_feature)\n",
    "            initial_features.append(best_feature)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return best_features\n",
    "\n",
    "# Logistic Regression\n",
    "log_reg = LogisticRegression(max_iter=10000)\n",
    "best_features_log_reg = forward_feature_selection(log_reg, X_train, y_train, X_val, y_val)\n",
    "\n",
    "# Decision Tree\n",
    "tree_model = DecisionTreeClassifier(random_state=42, max_leaf_nodes=5)\n",
    "best_features_tree = forward_feature_selection(tree_model, X_train, y_train, X_val, y_val)\n",
    "\n",
    "# XGBoost\n",
    "xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "best_features_xgb = forward_feature_selection(xgb_model, X_train, y_train, X_val, y_val)\n",
    "\n",
    "# Null Model\n",
    "class NullModel:\n",
    "    def fit(self, X, y):\n",
    "        self.mode = y.mode()[0]\n",
    "    def predict(self, X):\n",
    "        return np.full(len(X), self.mode)\n",
    "\n",
    "null_model = NullModel()\n",
    "null_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate models\n",
    "metrics = {\n",
    "    'Model': [],\n",
    "    'Dataset': [],\n",
    "    'Accuracy': [],\n",
    "    'Precision': [],\n",
    "    'Recall': [],\n",
    "    'Specificity': [],\n",
    "    'F1': []\n",
    "}\n",
    "\n",
    "# Logistic Regression\n",
    "log_reg.fit(X_train[best_features_log_reg], y_train)\n",
    "y_test_pred = log_reg.predict(X_test[best_features_log_reg])\n",
    "accuracy, precision, recall, specificity, f1 = calculate_metrics(y_test, y_test_pred)\n",
    "metrics['Model'].append('Logistic Regression')\n",
    "metrics['Dataset'].append('Test')\n",
    "metrics['Accuracy'].append(accuracy)\n",
    "metrics['Precision'].append(precision)\n",
    "metrics['Recall'].append(recall)\n",
    "metrics['Specificity'].append(specificity)\n",
    "metrics['F1'].append(f1)\n",
    "# Plot confusion matrix\n",
    "plot_confusion_matrix(log_reg, X_test[best_features_log_reg], y_test, display_labels=['Not Recovered', 'Recovered'])\n",
    "plt.title('Confusion Matrix for Logistic Regression (Test)')\n",
    "plt.show()\n",
    "\n",
    "# Decision Tree\n",
    "tree_model.fit(X_train[best_features_tree], y_train)\n",
    "y_test_pred = tree_model.predict(X_test[best_features_tree])\n",
    "accuracy, precision, recall, specificity, f1 = calculate_metrics(y_test, y_test_pred)\n",
    "metrics['Model'].append('Decision Tree')\n",
    "metrics['Dataset'].append('Test')\n",
    "metrics['Accuracy'].append(accuracy)\n",
    "metrics['Precision'].append(precision)\n",
    "metrics['Recall'].append(recall)\n",
    "metrics['Specificity'].append(specificity)\n",
    "metrics['F1'].append(f1)\n",
    "# Plot confusion matrix\n",
    "plot_confusion_matrix(tree_model, X_test[best_features_tree], y_test, display_labels=['Not Recovered', 'Recovered'])\n",
    "plt.title('Confusion Matrix for Decision Tree (Test)')\n",
    "plt.show()\n",
    "\n",
    "# XGBoost\n",
    "xgb_model.fit(X_train[best_features_xgb], y_train)\n",
    "y_test_pred = xgb_model.predict(X_test[best_features_xgb])\n",
    "accuracy, precision, recall, specificity, f1 = calculate_metrics(y_test, y_test_pred)\n",
    "metrics['Model'].append('XGBoost')\n",
    "metrics['Dataset'].append('Test')\n",
    "metrics['Accuracy'].append(accuracy)\n",
    "metrics['Precision'].append(precision)\n",
    "metrics['Recall'].append(recall)\n",
    "metrics['Specificity'].append(specificity)\n",
    "metrics['F1'].append(f1)\n",
    "# Plot confusion matrix\n",
    "plot_confusion_matrix(xgb_model, X_test[best_features_xgb], y_test, display_labels=['Not Recovered', 'Recovered'])\n",
    "plt.title('Confusion Matrix for XGBoost (Test)')\n",
    "plt.show()\n",
    "\n",
    "# Null Model\n",
    "y_test_pred = null_model.predict(X_test)\n",
    "accuracy, precision, recall, specificity, f1 = calculate_metrics(y_test, y_test_pred)\n",
    "metrics['Model'].append('Null Model')\n",
    "metrics['Dataset'].append('Test')\n",
    "metrics['Accuracy'].append(accuracy)\n",
    "metrics['Precision'].append(precision)\n",
    "metrics['Recall'].append(recall)\n",
    "metrics['Specificity'].append(specificity)\n",
    "metrics['F1'].append(f1)\n",
    "# Plot confusion matrix\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "fig, ax = plt.subplots()\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax)\n",
    "ax.set(xlabel='Predicted', ylabel='True', title='Confusion Matrix for Null Model (Test)')\n",
    "ax.set_xticklabels(['Not Recovered', 'Recovered'])\n",
    "ax.set_yticklabels(['Not Recovered', 'Recovered'])\n",
    "plt.show()\n",
    "\n",
    "# Convert metrics to DataFrame\n",
    "metrics_df = pd.DataFrame(metrics)\n",
    "\n",
    "# Display the results\n",
    "print(metrics_df)\n",
    "\n",
    "# Plot the Decision Tree\n",
    "plt.figure(figsize=(20,10))\n",
    "plot_tree(tree_model, feature_names=best_features_tree, class_names=['Not Recovered', 'Recovered'], filled=True, rounded=True, fontsize=10)\n",
    "plt.title('Decision Tree')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensionality Reduction - PCA\n",
    "Leidt tot een significante prestatiereductie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, plot_confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import RFE\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Assuming data_clean is already defined and clean\n",
    "\n",
    "# Select the features and target variable\n",
    "X = data_clean.drop(columns=['T5', 'T5_relative', 'T5_recovered'])\n",
    "y = data_clean['T5_recovered']\n",
    "\n",
    "# Perform PCA on the input features to reduce dimensionality\n",
    "pca = PCA(n_components=0.95)  # Retain 95% of the variance\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Function to calculate metrics\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    specificity = tn / (tn + fp)\n",
    "    return accuracy, precision, recall, specificity, f1\n",
    "\n",
    "# Initialize models\n",
    "log_reg = LogisticRegression(max_iter=10000)\n",
    "tree_model = DecisionTreeClassifier(random_state=42, max_leaf_nodes=5)\n",
    "xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "\n",
    "# Apply RFE to select the most important features\n",
    "rfe_log_reg = RFE(log_reg, n_features_to_select=10)\n",
    "X_train_rfe_log_reg = rfe_log_reg.fit_transform(X_train, y_train)\n",
    "X_test_rfe_log_reg = rfe_log_reg.transform(X_test)\n",
    "\n",
    "rfe_tree = RFE(tree_model, n_features_to_select=10)\n",
    "X_train_rfe_tree = rfe_tree.fit_transform(X_train, y_train)\n",
    "X_test_rfe_tree = rfe_tree.transform(X_test)\n",
    "\n",
    "rfe_xgb = RFE(xgb_model, n_features_to_select=10)\n",
    "X_train_rfe_xgb = rfe_xgb.fit_transform(X_train, y_train)\n",
    "X_test_rfe_xgb = rfe_xgb.transform(X_test)\n",
    "\n",
    "# Evaluate models\n",
    "metrics = {\n",
    "    'Model': [],\n",
    "    'Dataset': [],\n",
    "    'Accuracy': [],\n",
    "    'Precision': [],\n",
    "    'Recall': [],\n",
    "    'Specificity': [],\n",
    "    'F1': []\n",
    "}\n",
    "\n",
    "# Logistic Regression\n",
    "log_reg.fit(X_train_rfe_log_reg, y_train)\n",
    "y_test_pred = log_reg.predict(X_test_rfe_log_reg)\n",
    "accuracy, precision, recall, specificity, f1 = calculate_metrics(y_test, y_test_pred)\n",
    "metrics['Model'].append('Logistic Regression')\n",
    "metrics['Dataset'].append('Test')\n",
    "metrics['Accuracy'].append(accuracy)\n",
    "metrics['Precision'].append(precision)\n",
    "metrics['Recall'].append(recall)\n",
    "metrics['Specificity'].append(specificity)\n",
    "metrics['F1'].append(f1)\n",
    "# Plot confusion matrix\n",
    "plot_confusion_matrix(log_reg, X_test_rfe_log_reg, y_test, display_labels=['Not Recovered', 'Recovered'])\n",
    "plt.title('Confusion Matrix for Logistic Regression (Test)')\n",
    "plt.show()\n",
    "\n",
    "# Decision Tree\n",
    "tree_model.fit(X_train_rfe_tree, y_train)\n",
    "y_test_pred = tree_model.predict(X_test_rfe_tree)\n",
    "accuracy, precision, recall, specificity, f1 = calculate_metrics(y_test, y_test_pred)\n",
    "metrics['Model'].append('Decision Tree')\n",
    "metrics['Dataset'].append('Test')\n",
    "metrics['Accuracy'].append(accuracy)\n",
    "metrics['Precision'].append(precision)\n",
    "metrics['Recall'].append(recall)\n",
    "metrics['Specificity'].append(specificity)\n",
    "metrics['F1'].append(f1)\n",
    "# Plot confusion matrix\n",
    "plot_confusion_matrix(tree_model, X_test_rfe_tree, y_test, display_labels=['Not Recovered', 'Recovered'])\n",
    "plt.title('Confusion Matrix for Decision Tree (Test)')\n",
    "plt.show()\n",
    "\n",
    "# XGBoost\n",
    "xgb_model.fit(X_train_rfe_xgb, y_train)\n",
    "y_test_pred = xgb_model.predict(X_test_rfe_xgb)\n",
    "accuracy, precision, recall, specificity, f1 = calculate_metrics(y_test, y_test_pred)\n",
    "metrics['Model'].append('XGBoost')\n",
    "metrics['Dataset'].append('Test')\n",
    "metrics['Accuracy'].append(accuracy)\n",
    "metrics['Precision'].append(precision)\n",
    "metrics['Recall'].append(recall)\n",
    "metrics['Specificity'].append(specificity)\n",
    "metrics['F1'].append(f1)\n",
    "# Plot confusion matrix\n",
    "plot_confusion_matrix(xgb_model, X_test_rfe_xgb, y_test, display_labels=['Not Recovered', 'Recovered'])\n",
    "plt.title('Confusion Matrix for XGBoost (Test)')\n",
    "plt.show()\n",
    "\n",
    "# Null Model\n",
    "class NullModel:\n",
    "    def fit(self, X, y):\n",
    "        self.mode = y.mode()[0]\n",
    "    def predict(self, X):\n",
    "        return np.full(len(X), self.mode)\n",
    "\n",
    "null_model = NullModel()\n",
    "null_model.fit(X_train, y_train)\n",
    "\n",
    "y_test_pred = null_model.predict(X_test)\n",
    "accuracy, precision, recall, specificity, f1 = calculate_metrics(y_test, y_test_pred)\n",
    "metrics['Model'].append('Null Model')\n",
    "metrics['Dataset'].append('Test')\n",
    "metrics['Accuracy'].append(accuracy)\n",
    "metrics['Precision'].append(precision)\n",
    "metrics['Recall'].append(recall)\n",
    "metrics['Specificity'].append(specificity)\n",
    "metrics['F1'].append(f1)\n",
    "# Plot confusion matrix\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "fig, ax = plt.subplots()\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax)\n",
    "ax.set(xlabel='Predicted', ylabel='True', title='Confusion Matrix for Null Model (Test)')\n",
    "ax.set_xticklabels(['Not Recovered', 'Recovered'])\n",
    "ax.set_yticklabels(['Not Recovered', 'Recovered'])\n",
    "plt.show()\n",
    "\n",
    "# Convert metrics to DataFrame\n",
    "metrics_df = pd.DataFrame(metrics)\n",
    "\n",
    "# Display the results\n",
    "print(metrics_df)\n",
    "\n",
    "# Plot the Decision Tree\n",
    "plt.figure(figsize=(20,10))\n",
    "# Since RFE was applied to PCA components, we can just display the component indices\n",
    "plot_tree(tree_model, feature_names=[f'PCA{i+1}' for i in range(X_train_rfe_tree.shape[1])], class_names=['Not Recovered', 'Recovered'], filled=True, rounded=True, fontsize=10)\n",
    "plt.title('Decision Tree')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, plot_confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import RFE\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Assuming data_clean is already defined and clean\n",
    "\n",
    "# Select the features and target variable\n",
    "X = data_clean.drop(columns=['T5', 'T5_relative', 'T5_recovered'])\n",
    "y = data_clean['T5_recovered']\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Further split the training data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.3, random_state=42)\n",
    "\n",
    "# Perform PCA on the training set and apply the transformation to the validation and test sets\n",
    "pca = PCA(n_components=0.95)  # Retain 95% of the variance\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_val_pca = pca.transform(X_val)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "# Function to calculate metrics\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    specificity = tn / (tn + fp)\n",
    "    return accuracy, precision, recall, specificity, f1\n",
    "\n",
    "# Initialize models\n",
    "log_reg = LogisticRegression(max_iter=10000)\n",
    "tree_model = DecisionTreeClassifier(random_state=42)\n",
    "xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "\n",
    "# Hyperparameter tuning using GridSearchCV with k-fold cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Logistic Regression hyperparameters\n",
    "log_reg_params = {'C': [0.01, 0.1, 1, 10, 100]}\n",
    "log_reg_cv = GridSearchCV(log_reg, log_reg_params, cv=kf, scoring='accuracy')\n",
    "log_reg_cv.fit(X_train_pca, y_train)\n",
    "best_log_reg = log_reg_cv.best_estimator_\n",
    "\n",
    "# Decision Tree hyperparameters\n",
    "tree_params = {'max_depth': [3, 5, 7, 10], 'max_leaf_nodes': [5, 10, 20, 30]}\n",
    "tree_cv = GridSearchCV(tree_model, tree_params, cv=kf, scoring='accuracy')\n",
    "tree_cv.fit(X_train_pca, y_train)\n",
    "best_tree = tree_cv.best_estimator_\n",
    "\n",
    "# XGBoost hyperparameters\n",
    "xgb_params = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'subsample': [0.7, 0.8, 0.9],\n",
    "    'colsample_bytree': [0.7, 0.8, 0.9]\n",
    "}\n",
    "xgb_cv = GridSearchCV(xgb_model, xgb_params, cv=kf, scoring='accuracy')\n",
    "xgb_cv.fit(X_train_pca, y_train)\n",
    "best_xgb = xgb_cv.best_estimator_\n",
    "\n",
    "# Apply RFE to select the most important features\n",
    "rfe_log_reg = RFE(best_log_reg, n_features_to_select=10)\n",
    "X_train_rfe_log_reg = rfe_log_reg.fit_transform(X_train_pca, y_train)\n",
    "X_val_rfe_log_reg = rfe_log_reg.transform(X_val_pca)\n",
    "X_test_rfe_log_reg = rfe_log_reg.transform(X_test_pca)\n",
    "\n",
    "rfe_tree = RFE(best_tree, n_features_to_select=10)\n",
    "X_train_rfe_tree = rfe_tree.fit_transform(X_train_pca, y_train)\n",
    "X_val_rfe_tree = rfe_tree.transform(X_val_pca)\n",
    "X_test_rfe_tree = rfe_tree.transform(X_test_pca)\n",
    "\n",
    "rfe_xgb = RFE(best_xgb, n_features_to_select=10)\n",
    "X_train_rfe_xgb = rfe_xgb.fit_transform(X_train_pca, y_train)\n",
    "X_val_rfe_xgb = rfe_xgb.transform(X_val_pca)\n",
    "X_test_rfe_xgb = rfe_xgb.transform(X_test_pca)\n",
    "\n",
    "# Train the best models using the selected features\n",
    "best_log_reg.fit(X_train_rfe_log_reg, y_train)\n",
    "best_tree.fit(X_train_rfe_tree, y_train)\n",
    "best_xgb.fit(X_train_rfe_xgb, y_train)\n",
    "\n",
    "# Evaluate models on the test set\n",
    "metrics = {\n",
    "    'Model': [],\n",
    "    'Dataset': [],\n",
    "    'Accuracy': [],\n",
    "    'Precision': [],\n",
    "    'Recall': [],\n",
    "    'Specificity': [],\n",
    "    'F1': []\n",
    "}\n",
    "\n",
    "# Logistic Regression\n",
    "y_test_pred = best_log_reg.predict(X_test_rfe_log_reg)\n",
    "accuracy, precision, recall, specificity, f1 = calculate_metrics(y_test, y_test_pred)\n",
    "metrics['Model'].append('Logistic Regression')\n",
    "metrics['Dataset'].append('Test')\n",
    "metrics['Accuracy'].append(accuracy)\n",
    "metrics['Precision'].append(precision)\n",
    "metrics['Recall'].append(recall)\n",
    "metrics['Specificity'].append(specificity)\n",
    "metrics['F1'].append(f1)\n",
    "# Plot confusion matrix\n",
    "plot_confusion_matrix(best_log_reg, X_test_rfe_log_reg, y_test, display_labels=['Not Recovered', 'Recovered'])\n",
    "plt.title('Confusion Matrix for Logistic Regression (Test)')\n",
    "plt.show()\n",
    "\n",
    "# Decision Tree\n",
    "y_test_pred = best_tree.predict(X_test_rfe_tree)\n",
    "accuracy, precision, recall, specificity, f1 = calculate_metrics(y_test, y_test_pred)\n",
    "metrics['Model'].append('Decision Tree')\n",
    "metrics['Dataset'].append('Test')\n",
    "metrics['Accuracy'].append(accuracy)\n",
    "metrics['Precision'].append(precision)\n",
    "metrics['Recall'].append(recall)\n",
    "metrics['Specificity'].append(specificity)\n",
    "metrics['F1'].append(f1)\n",
    "# Plot confusion matrix\n",
    "plot_confusion_matrix(best_tree, X_test_rfe_tree, y_test, display_labels=['Not Recovered', 'Recovered'])\n",
    "plt.title('Confusion Matrix for Decision Tree (Test)')\n",
    "plt.show()\n",
    "\n",
    "# XGBoost\n",
    "y_test_pred = best_xgb.predict(X_test_rfe_xgb)\n",
    "accuracy, precision, recall, specificity, f1 = calculate_metrics(y_test, y_test_pred)\n",
    "metrics['Model'].append('XGBoost')\n",
    "metrics['Dataset'].append('Test')\n",
    "metrics['Accuracy'].append(accuracy)\n",
    "metrics['Precision'].append(precision)\n",
    "metrics['Recall'].append(recall)\n",
    "metrics['Specificity'].append(specificity)\n",
    "metrics['F1'].append(f1)\n",
    "# Plot confusion matrix\n",
    "plot_confusion_matrix(best_xgb, X_test_rfe_xgb, y_test, display_labels=['Not Recovered', 'Recovered'])\n",
    "plt.title('Confusion Matrix for XGBoost (Test)')\n",
    "plt.show()\n",
    "\n",
    "# Null Model\n",
    "class NullModel:\n",
    "    def fit(self, X, y):\n",
    "        self.mode = y.mode()[0]\n",
    "    def predict(self, X):\n",
    "        return np.full(len(X), self.mode)\n",
    "\n",
    "null_model = NullModel()\n",
    "null_model.fit(X_train_pca, y_train)\n",
    "\n",
    "y_test_pred = null_model.predict(X_test_pca)\n",
    "accuracy, precision, recall, specificity, f1 = calculate_metrics(y_test, y_test_pred)\n",
    "metrics['Model'].append('Null Model')\n",
    "metrics['Dataset'].append('Test')\n",
    "metrics['Accuracy'].append(accuracy)\n",
    "metrics['Precision'].append(precision)\n",
    "metrics['Recall'].append(recall)\n",
    "metrics['Specificity'].append(specificity)\n",
    "metrics['F1'].append(f1)\n",
    "# Plot confusion matrix\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "fig, ax = plt.subplots()\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax)\n",
    "ax.set(xlabel='Predicted', ylabel='True', title='Confusion Matrix for Null Model (Test)')\n",
    "ax.set_xticklabels(['Not Recovered', 'Recovered'])\n",
    "ax.set_yticklabels(['Not Recovered', 'Recovered'])\n",
    "plt.show()\n",
    "\n",
    "# Convert metrics to DataFrame\n",
    "metrics_df = pd.DataFrame(metrics)\n",
    "\n",
    "# Display the results\n",
    "print(metrics_df)\n",
    "\n",
    "# Plot the Decision Tree\n",
    "plt.figure(figsize=(20,10))\n",
    "# Since RFE was applied to PCA components, we can just display the component indices\n",
    "plot_tree(best_tree, feature_names=[f'PCA{i+1}' for i in range(X_train_rfe_tree.shape[1])], class_names=['Not Recovered', 'Recovered'], filled=True, rounded=True, fontsize=10)\n",
    "plt.title('Decision Tree')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################## Duurt 8 minunten ##########################\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, plot_confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import RFE\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Assuming data_clean is already defined and clean\n",
    "\n",
    "# Select the features and target variable\n",
    "X = data_clean.drop(columns=['T5', 'T5_relative', 'T5_recovered'])\n",
    "y = data_clean['T5_recovered']\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Further split the training data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.3, random_state=42)\n",
    "\n",
    "# Function to calculate metrics\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    specificity = tn / (tn + fp)\n",
    "    return accuracy, precision, recall, specificity, f1\n",
    "\n",
    "# Initialize models\n",
    "log_reg = LogisticRegression(max_iter=10000)\n",
    "tree_model = DecisionTreeClassifier(random_state=42)\n",
    "xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "\n",
    "# Create pipelines with PCA and model\n",
    "pipe_log_reg = Pipeline([('pca', PCA()), ('log_reg', log_reg)])\n",
    "pipe_tree = Pipeline([('pca', PCA()), ('tree', tree_model)])\n",
    "pipe_xgb = Pipeline([('pca', PCA()), ('xgb', xgb_model)])\n",
    "\n",
    "# Hyperparameter tuning using GridSearchCV with k-fold cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Logistic Regression hyperparameters including PCA n_components\n",
    "log_reg_params = {\n",
    "    'pca__n_components': [5, 10, 15, 20, 25, 30],\n",
    "    'log_reg__C': [0.01, 0.1, 1, 10, 100]\n",
    "}\n",
    "log_reg_cv = GridSearchCV(pipe_log_reg, log_reg_params, cv=kf, scoring='accuracy')\n",
    "log_reg_cv.fit(X_train, y_train)\n",
    "best_log_reg = log_reg_cv.best_estimator_\n",
    "\n",
    "# Decision Tree hyperparameters including PCA n_components\n",
    "tree_params = {\n",
    "    'pca__n_components': [5, 10, 15, 20, 25, 30],\n",
    "    'tree__max_depth': [3, 5, 7, 10],\n",
    "    'tree__max_leaf_nodes': [5, 10, 20, 30]\n",
    "}\n",
    "tree_cv = GridSearchCV(pipe_tree, tree_params, cv=kf, scoring='accuracy')\n",
    "tree_cv.fit(X_train, y_train)\n",
    "best_tree = tree_cv.best_estimator_\n",
    "\n",
    "# XGBoost hyperparameters including PCA n_components\n",
    "xgb_params = {\n",
    "    'pca__n_components': [5, 10, 15, 20, 25, 30],\n",
    "    'xgb__n_estimators': [100, 200, 300],\n",
    "    'xgb__learning_rate': [0.01, 0.1, 0.2],\n",
    "    'xgb__max_depth': [3, 5, 7],\n",
    "    'xgb__subsample': [0.7, 0.8, 0.9],\n",
    "    'xgb__colsample_bytree': [0.7, 0.8, 0.9]\n",
    "}\n",
    "xgb_cv = GridSearchCV(pipe_xgb, xgb_params, cv=kf, scoring='accuracy')\n",
    "xgb_cv.fit(X_train, y_train)\n",
    "best_xgb = xgb_cv.best_estimator_\n",
    "\n",
    "# Apply RFE to select the most important features\n",
    "rfe_log_reg = RFE(best_log_reg.named_steps['log_reg'], n_features_to_select=10)\n",
    "X_train_rfe_log_reg = rfe_log_reg.fit_transform(best_log_reg.named_steps['pca'].transform(X_train), y_train)\n",
    "X_val_rfe_log_reg = rfe_log_reg.transform(best_log_reg.named_steps['pca'].transform(X_val))\n",
    "X_test_rfe_log_reg = rfe_log_reg.transform(best_log_reg.named_steps['pca'].transform(X_test))\n",
    "\n",
    "rfe_tree = RFE(best_tree.named_steps['tree'], n_features_to_select=10)\n",
    "X_train_rfe_tree = rfe_tree.fit_transform(best_tree.named_steps['pca'].transform(X_train), y_train)\n",
    "X_val_rfe_tree = rfe_tree.transform(best_tree.named_steps['pca'].transform(X_val))\n",
    "X_test_rfe_tree = rfe_tree.transform(best_tree.named_steps['pca'].transform(X_test))\n",
    "\n",
    "rfe_xgb = RFE(best_xgb.named_steps['xgb'], n_features_to_select=10)\n",
    "X_train_rfe_xgb = rfe_xgb.fit_transform(best_xgb.named_steps['pca'].transform(X_train), y_train)\n",
    "X_val_rfe_xgb = rfe_xgb.transform(best_xgb.named_steps['pca'].transform(X_val))\n",
    "X_test_rfe_xgb = rfe_xgb.transform(best_xgb.named_steps['pca'].transform(X_test))\n",
    "\n",
    "# Train the best models using the selected features\n",
    "best_log_reg.named_steps['log_reg'].fit(X_train_rfe_log_reg, y_train)\n",
    "best_tree.named_steps['tree'].fit(X_train_rfe_tree, y_train)\n",
    "best_xgb.named_steps['xgb'].fit(X_train_rfe_xgb, y_train)\n",
    "\n",
    "# Evaluate models on the test set\n",
    "metrics = {\n",
    "    'Model': [],\n",
    "    'Dataset': [],\n",
    "    'Accuracy': [],\n",
    "    'Precision': [],\n",
    "    'Recall': [],\n",
    "    'Specificity': [],\n",
    "    'F1': []\n",
    "}\n",
    "\n",
    "# Logistic Regression\n",
    "y_test_pred = best_log_reg.named_steps['log_reg'].predict(X_test_rfe_log_reg)\n",
    "accuracy, precision, recall, specificity, f1 = calculate_metrics(y_test, y_test_pred)\n",
    "metrics['Model'].append('Logistic Regression')\n",
    "metrics['Dataset'].append('Test')\n",
    "metrics['Accuracy'].append(accuracy)\n",
    "metrics['Precision'].append(precision)\n",
    "metrics['Recall'].append(recall)\n",
    "metrics['Specificity'].append(specificity)\n",
    "metrics['F1'].append(f1)\n",
    "# Plot confusion matrix\n",
    "plot_confusion_matrix(best_log_reg.named_steps['log_reg'], X_test_rfe_log_reg, y_test, display_labels=['Not Recovered', 'Recovered'])\n",
    "plt.title('Confusion Matrix for Logistic Regression (Test)')\n",
    "plt.show()\n",
    "\n",
    "# Decision Tree\n",
    "y_test_pred = best_tree.named_steps['tree'].predict(X_test_rfe_tree)\n",
    "accuracy, precision, recall, specificity, f1 = calculate_metrics(y_test, y_test_pred)\n",
    "metrics['Model'].append('Decision Tree')\n",
    "metrics['Dataset'].append('Test')\n",
    "metrics['Accuracy'].append(accuracy)\n",
    "metrics['Precision'].append(precision)\n",
    "metrics['Recall'].append(recall)\n",
    "metrics['Specificity'].append(specificity)\n",
    "metrics['F1'].append(f1)\n",
    "# Plot confusion matrix\n",
    "plot_confusion_matrix(best_tree.named_steps['tree'], X_test_rfe_tree, y_test, display_labels=['Not Recovered', 'Recovered'])\n",
    "plt.title('Confusion Matrix for Decision Tree (Test)')\n",
    "plt.show()\n",
    "\n",
    "# XGBoost\n",
    "y_test_pred = best_xgb.named_steps['xgb'].predict(X_test_rfe_xgb)\n",
    "accuracy, precision, recall, specificity, f1 = calculate_metrics(y_test, y_test_pred)\n",
    "metrics['Model'].append('XGBoost')\n",
    "metrics['Dataset'].append('Test')\n",
    "metrics['Accuracy'].append(accuracy)\n",
    "metrics['Precision'].append(precision)\n",
    "metrics['Recall'].append(recall)\n",
    "metrics['Specificity'].append(specificity)\n",
    "metrics['F1'].append(f1)\n",
    "# Plot confusion matrix\n",
    "plot_confusion_matrix(best_xgb.named_steps['xgb'], X_test_rfe_xgb, y_test, display_labels=['Not Recovered', 'Recovered'])\n",
    "plt.title('Confusion Matrix for XGBoost (Test)')\n",
    "plt.show()\n",
    "\n",
    "# Null Model\n",
    "class NullModel:\n",
    "    def fit(self, X, y):\n",
    "        self.mode = y.mode()[0]\n",
    "    def predict(self, X):\n",
    "        return np.full(len(X), self.mode)\n",
    "\n",
    "null_model = NullModel()\n",
    "null_model.fit(X_train, y_train)\n",
    "\n",
    "y_test_pred = null_model.predict(X_test)\n",
    "accuracy, precision, recall, specificity, f1 = calculate_metrics(y_test, y_test_pred)\n",
    "metrics['Model'].append('Null Model')\n",
    "metrics['Dataset'].append('Test')\n",
    "metrics['Accuracy'].append(accuracy)\n",
    "metrics['Precision'].append(precision)\n",
    "metrics['Recall'].append(recall)\n",
    "metrics['Specificity'].append(specificity)\n",
    "metrics['F1'].append(f1)\n",
    "# Plot confusion matrix\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "fig, ax = plt.subplots()\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax)\n",
    "ax.set(xlabel='Predicted', ylabel='True', title='Confusion Matrix for Null Model (Test)')\n",
    "ax.set_xticklabels(['Not Recovered', 'Recovered'])\n",
    "ax.set_yticklabels(['Not Recovered', 'Recovered'])\n",
    "plt.show()\n",
    "\n",
    "# Convert metrics to DataFrame\n",
    "metrics_df = pd.DataFrame(metrics)\n",
    "\n",
    "# Display the results\n",
    "print(metrics_df)\n",
    "\n",
    "# Plot the Decision Tree\n",
    "plt.figure(figsize=(20,10))\n",
    "# Since RFE was applied to PCA components, we can just display the component indices\n",
    "plot_tree(best_tree.named_steps['tree'], feature_names=[f'PCA{i+1}' for i in range(X_train_rfe_tree.shape[1])], class_names=['Not Recovered', 'Recovered'], filled=True, rounded=True, fontsize=10)\n",
    "plt.title('Decision Tree')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "2022.10.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
