{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T0</th>\n",
       "      <th>T2</th>\n",
       "      <th>T3</th>\n",
       "      <th>T4</th>\n",
       "      <th>T5</th>\n",
       "      <th>T6</th>\n",
       "      <th>patientnummer</th>\n",
       "      <th>T2_relative</th>\n",
       "      <th>T3_relative</th>\n",
       "      <th>T4_relative</th>\n",
       "      <th>T5_relative</th>\n",
       "      <th>T6_relative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50.944</td>\n",
       "      <td>30.166</td>\n",
       "      <td>33.454</td>\n",
       "      <td>48.386</td>\n",
       "      <td>48.701</td>\n",
       "      <td>49.700</td>\n",
       "      <td>pp_OPRAH_VU_01</td>\n",
       "      <td>0.592140</td>\n",
       "      <td>0.656682</td>\n",
       "      <td>0.949788</td>\n",
       "      <td>0.955971</td>\n",
       "      <td>0.975581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44.867</td>\n",
       "      <td>39.681</td>\n",
       "      <td>39.962</td>\n",
       "      <td>42.242</td>\n",
       "      <td>42.103</td>\n",
       "      <td>45.788</td>\n",
       "      <td>pp_OPRAH_VU_02</td>\n",
       "      <td>0.884414</td>\n",
       "      <td>0.890677</td>\n",
       "      <td>0.941494</td>\n",
       "      <td>0.938396</td>\n",
       "      <td>1.020527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44.619</td>\n",
       "      <td>35.152</td>\n",
       "      <td>44.951</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pp_OPRAH_VU_03</td>\n",
       "      <td>0.787826</td>\n",
       "      <td>1.007441</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44.352</td>\n",
       "      <td>38.637</td>\n",
       "      <td>46.973</td>\n",
       "      <td>48.701</td>\n",
       "      <td>48.515</td>\n",
       "      <td>48.701</td>\n",
       "      <td>pp_OPRAH_VU_04</td>\n",
       "      <td>0.871144</td>\n",
       "      <td>1.059095</td>\n",
       "      <td>1.098056</td>\n",
       "      <td>1.093863</td>\n",
       "      <td>1.098056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54.644</td>\n",
       "      <td>23.280</td>\n",
       "      <td>28.457</td>\n",
       "      <td>40.981</td>\n",
       "      <td>45.347</td>\n",
       "      <td>45.348</td>\n",
       "      <td>pp_OPRAH_VU_06</td>\n",
       "      <td>0.426030</td>\n",
       "      <td>0.520771</td>\n",
       "      <td>0.749963</td>\n",
       "      <td>0.829862</td>\n",
       "      <td>0.829881</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       T0      T2      T3      T4      T5      T6   patientnummer  \\\n",
       "0  50.944  30.166  33.454  48.386  48.701  49.700  pp_OPRAH_VU_01   \n",
       "1  44.867  39.681  39.962  42.242  42.103  45.788  pp_OPRAH_VU_02   \n",
       "2  44.619  35.152  44.951     NaN     NaN     NaN  pp_OPRAH_VU_03   \n",
       "3  44.352  38.637  46.973  48.701  48.515  48.701  pp_OPRAH_VU_04   \n",
       "4  54.644  23.280  28.457  40.981  45.347  45.348  pp_OPRAH_VU_06   \n",
       "\n",
       "   T2_relative  T3_relative  T4_relative  T5_relative  T6_relative  \n",
       "0     0.592140     0.656682     0.949788     0.955971     0.975581  \n",
       "1     0.884414     0.890677     0.941494     0.938396     1.020527  \n",
       "2     0.787826     1.007441          NaN          NaN          NaN  \n",
       "3     0.871144     1.059095     1.098056     1.093863     1.098056  \n",
       "4     0.426030     0.520771     0.749963     0.829862     0.829881  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import statsmodels.api as sm\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "uitkomstmaat_df = pd.read_csv('../Export/uitkomstmaat.csv', delimiter=';')\n",
    "uitkomstmaat_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the new voorspelers file with semicolon separator\n",
    "voorspellers_df = pd.read_csv('../Export/Voorspellers.csv', delimiter=';')\n",
    "\n",
    "# Load the uitkomstmaat data_clean_cleanset\n",
    "uitkomstmaat_df = pd.read_csv('../Export/uitkomstmaat.csv', delimiter=';')\n",
    "uitkomstmaat_vars = uitkomstmaat_df[[\"patientnummer\", \"T0\", \"T5\"]]\n",
    "\n",
    "ML_df = pd.merge(voorspellers_df, uitkomstmaat_vars, left_on='Participant Id', right_on='patientnummer', how='inner')\n",
    "ML_df.drop(columns=['Participant Id', 'patientnummer'], inplace=True)\n",
    "ML_df.to_csv('../export/ML_df.csv', index=False, sep=';')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\melmora\\Anaconda3\\lib\\site-packages\\sklearn\\impute\\_base.py:49: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode = stats.mode(array)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Assume ML_df is your DataFrame\n",
    "# data_clean is data met Imputation\n",
    "# data is data zonder imputation\n",
    "data_clean = ML_df.copy()\n",
    "data = ML_df.copy()\n",
    "\n",
    "# Identify columns\n",
    "continuous_columns = [\n",
    "    'T0_age', 'T0_BMI', 'T0_BIA_VVM_kg', 'T0_BIA_vetmassa_kg', \n",
    "    'Time_pretreat_OK', 'OK_Duration_min', 'Length_of_stay', \n",
    "    'T0_30SCST', 'T0_fatigue', 'T0_protein_perc', 'T0_kcal_perc', \n",
    "    'T0_CT_SMI', 'T0_CT_SMRA', 't0_gses_totaal_score', \n",
    "    'T0_participation_ability', 'T0_participation_satisfaction', \n",
    "    't0_EQ_5D_5L_beschrijvend-systeem_score', 'T0_pain', 'T0'\n",
    "]\n",
    "\n",
    "categorical_columns = [\n",
    "    'T0_VVMI_per', 'Education', 'household', 'T0_Tumorsize', \n",
    "    'T0_diseaseburden_cat', 'T0_selfcare', 'T0_Locusofcontrol_cat',\n",
    "    'T0_socialsupport_cat', 'T0_coping_cat', 'AMEXO_8_day1', \n",
    "    'AMEXO_9_day2', 'AMEXO_10_day3', 'T0_sondevoeding', 'T0_protein_cat',\n",
    "    'T0_kcal_cat', 'T0_ASM_low', 'T0_anxiety_cat', 'T0_depression_cat'\n",
    "]\n",
    "\n",
    "# Remove rows with missing values in T5\n",
    "if 'T5_relative' in data_clean.columns:\n",
    "    data_clean = data_clean.dropna(subset=['T5'])\n",
    "\n",
    "# Remove rows where T5 > 80\n",
    "if 'T5' in data_clean.columns:\n",
    "    data_clean = data_clean[data_clean['T5'] <= 80]\n",
    "\n",
    "# Initialize the SimpleImputer with median strategy for continuous variables\n",
    "median_imputer = SimpleImputer(strategy='median')\n",
    "\n",
    "# Apply median imputation excluding 'T5'\n",
    "existing_continuous_columns = [col for col in continuous_columns if col in data_clean.columns]\n",
    "if existing_continuous_columns:\n",
    "    data_clean[existing_continuous_columns] = median_imputer.fit_transform(data_clean[existing_continuous_columns])\n",
    "\n",
    "# Initialize the SimpleImputer with mode strategy for categorical variables\n",
    "mode_imputer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "# Apply mode imputation to categorical columns\n",
    "existing_categorical_columns = [col for col in categorical_columns if col in data_clean.columns]\n",
    "if existing_categorical_columns:\n",
    "    data_clean[existing_categorical_columns] = mode_imputer.fit_transform(data_clean[existing_categorical_columns])\n",
    "\n",
    "# Fill missing values for specific columns with 0\n",
    "for col in ['Complications_CCI', 'readmission_30days', 'Time_OK_posttreat']:\n",
    "    if col in data_clean.columns:\n",
    "        data_clean[col] = data_clean[col].fillna(0)\n",
    "\n",
    "# Verify no remaining missing values except for T5\n",
    "missing_values_final_check = data_clean.isnull().sum()\n",
    "data_clean\n",
    "\n",
    "# Output the missing values check\n",
    "missing_values_final_check.sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Controleer op NaN of oneindige waarden en verwijder deze uit de kolom T5\n",
    "t5_cleaned = data_clean['T5'].replace([np.inf, -np.inf], np.nan).dropna()\n",
    "t5_cleaned.hist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Train / Test Split\n",
    "- Hier pak ik 4 modellen, LR, Lasso, XGboost en Nul model en ik train deze modellen op de test en kijk naar de nauwkeurigheid op de test set. Dit is nog zonder parameter optimalisatie. Alle modellen. Inclusief de lasso regressie lijken het slechter te doen dan de null model.\n",
    "- Daarna heb ik een RFE benadering geprobeerd met een lineare regressie model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of patients in the test set: 32\n",
      "                Model Dataset       MAE      RMSE        R2\n",
      "0   Linear Regression   Train  2.477008  3.161081  0.789015\n",
      "1   Linear Regression    Test  7.477628  9.362080 -1.247339\n",
      "2    Lasso Regression   Train  4.153266  5.312445  0.404106\n",
      "3    Lasso Regression    Test  5.518221  6.700104 -0.151031\n",
      "4  XGBoost Regression   Train  0.000377  0.000529  1.000000\n",
      "5  XGBoost Regression    Test  5.196332  7.329485 -0.377434\n",
      "6          Null Model   Train  5.235296  6.881922  0.000000\n",
      "7          Null Model    Test  5.166496  6.259338 -0.004571\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming data_clean is already defined and clean\n",
    "\n",
    "# Select the features and target variable\n",
    "X = data_clean.drop(columns=['T5'])\n",
    "y = data_clean['T5']\n",
    "\n",
    "# Remove rows with NaN or infinite values in X or y\n",
    "mask = X.notna().all(axis=1) & np.isfinite(X).all(axis=1) & y.notna() & np.isfinite(y)\n",
    "X = X[mask]\n",
    "y = y[mask]\n",
    "\n",
    "# Perform a simple train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "print(f'Number of patients in the test set: {len(y_test)}')\n",
    "\n",
    "# Initialize models\n",
    "linear_reg = LinearRegression()\n",
    "lasso_reg = Lasso(alpha=10, max_iter=10000)\n",
    "xgb_reg = xgb.XGBRegressor(objective='reg:squarederror', eval_metric='rmse')\n",
    "\n",
    "# Train models\n",
    "linear_reg.fit(X_train, y_train)\n",
    "lasso_reg.fit(X_train, y_train)\n",
    "xgb_reg.fit(X_train, y_train)\n",
    "\n",
    "# Predict on train and test sets\n",
    "y_train_pred_linear = linear_reg.predict(X_train)\n",
    "y_test_pred_linear = linear_reg.predict(X_test)\n",
    "\n",
    "y_train_pred_lasso = lasso_reg.predict(X_train)\n",
    "y_test_pred_lasso = lasso_reg.predict(X_test)\n",
    "\n",
    "y_train_pred_xgb = xgb_reg.predict(X_train)\n",
    "y_test_pred_xgb = xgb_reg.predict(X_test)\n",
    "\n",
    "# Null model (predict the mean of the train set)\n",
    "y_train_pred_null = np.full_like(y_train, y_train.mean(), dtype=np.float64)\n",
    "y_test_pred_null = np.full_like(y_test, y_train.mean(), dtype=np.float64)\n",
    "\n",
    "# Define a function to calculate metrics\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return mae, rmse, r2\n",
    "\n",
    "# Calculate metrics for each model on train and test sets\n",
    "metrics = {\n",
    "    'Model': [],\n",
    "    'Dataset': [],\n",
    "    'MAE': [],\n",
    "    'RMSE': [],\n",
    "    'R2': []\n",
    "}\n",
    "\n",
    "for model_name, y_train_pred, y_test_pred in [\n",
    "    ('Linear Regression', y_train_pred_linear, y_test_pred_linear),\n",
    "    ('Lasso Regression', y_train_pred_lasso, y_test_pred_lasso),\n",
    "    ('XGBoost Regression', y_train_pred_xgb, y_test_pred_xgb),\n",
    "    ('Null Model', y_train_pred_null, y_test_pred_null)\n",
    "]:\n",
    "    for dataset, y_true, y_pred in [\n",
    "        ('Train', y_train, y_train_pred),\n",
    "        ('Test', y_test, y_test_pred)\n",
    "    ]:\n",
    "        mae, rmse, r2 = calculate_metrics(y_true, y_pred)\n",
    "        metrics['Model'].append(model_name)\n",
    "        metrics['Dataset'].append(dataset)\n",
    "        metrics['MAE'].append(mae)\n",
    "        metrics['RMSE'].append(rmse)\n",
    "        metrics['R2'].append(r2)\n",
    "\n",
    "# Convert metrics to a DataFrame for easy viewing\n",
    "metrics_df = pd.DataFrame(metrics)\n",
    "\n",
    "print(metrics_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: Index(['T0_Tumorsize', 'T0_CT_SMI', 'T0'], dtype='object')\n",
      "Train MAE: 4.225875014844661\n",
      "Train RMSE: 5.4113932560282345\n",
      "Train R2: 0.3750992179513407\n",
      "Test MAE: 4.928842469909662\n",
      "Test RMSE: 6.320821417686787\n",
      "Test R2: -0.11696796842261259\n",
      "                     Model Dataset       MAE      RMSE        R2\n",
      "0        Linear Regression   Train  2.477008  3.161081  0.789015\n",
      "1        Linear Regression    Test  7.477628  9.362080 -1.247339\n",
      "2         Lasso Regression   Train  4.153266  5.312445  0.404106\n",
      "3         Lasso Regression    Test  5.518221  6.700104 -0.151031\n",
      "4       XGBoost Regression   Train  0.000377  0.000529  1.000000\n",
      "5       XGBoost Regression    Test  5.196332  7.329485 -0.377434\n",
      "6               Null Model   Train  5.235296  6.881922  0.000000\n",
      "7               Null Model    Test  5.166496  6.259338 -0.004571\n",
      "8  Linear Regression - RFE   Train  4.225875  5.411393  0.375099\n",
      "9  Linear Regression - RFE    Test  4.928842  6.320821 -0.116968\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assuming data_clean is already defined and clean\n",
    "\n",
    "# Select the features and target variable\n",
    "X = data_clean.drop(columns=['T5'])\n",
    "y = data_clean['T5']\n",
    "\n",
    "# Remove rows with NaN or infinite values in X or y\n",
    "mask = X.notna().all(axis=1) & np.isfinite(X).all(axis=1) & y.notna() & np.isfinite(y)\n",
    "X = X[mask]\n",
    "y = y[mask]\n",
    "\n",
    "# Perform a simple train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Recursive Feature Elimination based on p-values\n",
    "def recursive_feature_elimination(X, y, threshold=0.05):\n",
    "    X = X.copy()\n",
    "    while True:\n",
    "        X = sm.add_constant(X)\n",
    "        model = sm.OLS(y, X).fit()\n",
    "        pvalues = model.pvalues[1:]  # exclude the intercept\n",
    "        max_pvalue = pvalues.max()\n",
    "        if max_pvalue > threshold:\n",
    "            feature_to_remove = pvalues.idxmax()\n",
    "            X = X.drop(columns=[feature_to_remove])\n",
    "        else:\n",
    "            break\n",
    "    return X.columns[1:]  # exclude the constant\n",
    "\n",
    "# Perform RFE on the training set\n",
    "selected_features = recursive_feature_elimination(X_train, y_train)\n",
    "\n",
    "# Train a linear regression model with selected features\n",
    "linear_reg = LinearRegression()\n",
    "linear_reg.fit(X_train[selected_features], y_train)\n",
    "\n",
    "# Predict on train and test sets\n",
    "y_train_pred = linear_reg.predict(X_train[selected_features])\n",
    "y_test_pred = linear_reg.predict(X_test[selected_features])\n",
    "\n",
    "# Define a function to calculate metrics\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return mae, rmse, r2\n",
    "\n",
    "# Calculate metrics for train and test sets\n",
    "train_mae, train_rmse, train_r2 = calculate_metrics(y_train, y_train_pred)\n",
    "test_mae, test_rmse, test_r2 = calculate_metrics(y_test, y_test_pred)\n",
    "\n",
    "# Print results\n",
    "print(\"Selected features:\", selected_features)\n",
    "print(f'Train MAE: {train_mae}')\n",
    "print(f'Train RMSE: {train_rmse}')\n",
    "print(f'Train R2: {train_r2}')\n",
    "print(f'Test MAE: {test_mae}')\n",
    "print(f'Test RMSE: {test_rmse}')\n",
    "print(f'Test R2: {test_r2}')\n",
    "\n",
    "# Add metrics to metrics_df\n",
    "new_metrics = {\n",
    "    'Model': ['Linear Regression - RFE', 'Linear Regression - RFE'],\n",
    "    'Dataset': ['Train', 'Test'],\n",
    "    'MAE': [train_mae, test_mae],\n",
    "    'RMSE': [train_rmse, test_rmse],\n",
    "    'R2': [train_r2, test_r2]\n",
    "}\n",
    "\n",
    "new_metrics_df = pd.DataFrame(new_metrics)\n",
    "\n",
    "# Assuming metrics_df is already defined from previous models\n",
    "metrics_df = pd.concat([metrics_df, new_metrics_df], ignore_index=True)\n",
    "print(metrics_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-Fold Cross Validation - train/validation set\n",
    "- Dataset wordt gesplitst in trainings- en testsets.\n",
    "- Er wordt een 5-voudige cross-validatie uitgevoerd met hyperparameter tuning voor zowel Lasso Regression als XGBoost Regression om de beste modelconfiguratie te vinden.\n",
    "- Het beste model wordt opnieuw getraind op de volledige trainingsset en geëvalueerd op de testset, waarbij de prestaties worden gemeten met MAE, RMSE en R².\n",
    "- Een null model, dat het gemiddelde van de trainingsset voorspelt, wordt gebruikt als benchmark om de prestaties van de regressiemodellen te vergelijken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Model Dataset       MAE      RMSE        R2\n",
      "0    Lasso Regression   Train  4.549965  5.604977  0.329590\n",
      "1    Lasso Regression    Test  4.805724  6.171891 -0.064952\n",
      "2  XGBoost Regression   Train  1.992920  2.617246  0.853822\n",
      "3  XGBoost Regression    Test  4.188396  5.816543  0.054147\n",
      "4          Null Model   Train  5.386419  6.845475  0.000000\n",
      "5          Null Model    Test  4.871789  6.088768 -0.036460\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "\n",
    "# Assuming data_clean is already cleaned and imputed\n",
    "\n",
    "# Remove rows with missing values in T5\n",
    "data_clean = data_clean.dropna(subset=['T5'])\n",
    "\n",
    "# Remove rows where T5 > 80\n",
    "data_clean = data_clean[data_clean['T5'] <= 80]\n",
    "\n",
    "# Split data into features (X) and target (y)\n",
    "X = data_clean.drop(columns=['T5'])\n",
    "y = data_clean['T5']\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Function to calculate metrics\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return mae, rmse, r2\n",
    "\n",
    "# Perform 5-fold cross-validation with hyperparameter tuning\n",
    "def perform_cv_and_tuning(model, param_grid, X_train, y_train):\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=kf, scoring='neg_mean_squared_error')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_model = grid_search.best_estimator_\n",
    "    return best_model\n",
    "\n",
    "# Lasso Regression\n",
    "lasso = Lasso(max_iter=10000)\n",
    "lasso_param_grid = {'alpha': np.logspace(-4, 5, 50)}\n",
    "best_lasso = perform_cv_and_tuning(lasso, lasso_param_grid, X_train, y_train)\n",
    "\n",
    "# XGBoost Regression\n",
    "xgb_reg = xgb.XGBRegressor(objective='reg:squarederror', eval_metric='rmse')\n",
    "xgb_param_grid = {\n",
    "    'n_estimators': [10, 50, 100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.1, 0.2, 1],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'subsample': [0.5, 0.7, 0.8, 0.9],\n",
    "    'colsample_bytree': [0.7, 0.8, 0.9]\n",
    "}\n",
    "best_xgb = perform_cv_and_tuning(xgb_reg, xgb_param_grid, X_train, y_train)\n",
    "\n",
    "# Null Model\n",
    "class NullModel:\n",
    "    def fit(self, X, y):\n",
    "        self.mean = y.mean()\n",
    "    def predict(self, X):\n",
    "        return np.full(len(X), self.mean)\n",
    "\n",
    "null_model = NullModel()\n",
    "null_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate models\n",
    "metrics = {\n",
    "    'Model': [],\n",
    "    'Dataset': [],\n",
    "    'MAE': [],\n",
    "    'RMSE': [],\n",
    "    'R2': []\n",
    "}\n",
    "\n",
    "# Lasso Regression\n",
    "y_train_pred_lasso = best_lasso.predict(X_train)\n",
    "y_test_pred_lasso = best_lasso.predict(X_test)\n",
    "train_mae, train_rmse, train_r2 = calculate_metrics(y_train, y_train_pred_lasso)\n",
    "test_mae, test_rmse, test_r2 = calculate_metrics(y_test, y_test_pred_lasso)\n",
    "metrics['Model'].extend(['Lasso Regression', 'Lasso Regression'])\n",
    "metrics['Dataset'].extend(['Train', 'Test'])\n",
    "metrics['MAE'].extend([train_mae, test_mae])\n",
    "metrics['RMSE'].extend([train_rmse, test_rmse])\n",
    "metrics['R2'].extend([train_r2, test_r2])\n",
    "\n",
    "# XGBoost Regression\n",
    "y_train_pred_xgb = best_xgb.predict(X_train)\n",
    "y_test_pred_xgb = best_xgb.predict(X_test)\n",
    "train_mae, train_rmse, train_r2 = calculate_metrics(y_train, y_train_pred_xgb)\n",
    "test_mae, test_rmse, test_r2 = calculate_metrics(y_test, y_test_pred_xgb)\n",
    "metrics['Model'].extend(['XGBoost Regression', 'XGBoost Regression'])\n",
    "metrics['Dataset'].extend(['Train', 'Test'])\n",
    "metrics['MAE'].extend([train_mae, test_mae])\n",
    "metrics['RMSE'].extend([train_rmse, test_rmse])\n",
    "metrics['R2'].extend([train_r2, test_r2])\n",
    "\n",
    "# Null Model\n",
    "y_train_pred_null = null_model.predict(X_train)\n",
    "y_test_pred_null = null_model.predict(X_test)\n",
    "train_mae, train_rmse, train_r2 = calculate_metrics(y_train, y_train_pred_null)\n",
    "test_mae, test_rmse, test_r2 = calculate_metrics(y_test, y_test_pred_null)\n",
    "metrics['Model'].extend(['Null Model', 'Null Model'])\n",
    "metrics['Dataset'].extend(['Train', 'Test'])\n",
    "metrics['MAE'].extend([train_mae, test_mae])\n",
    "metrics['RMSE'].extend([train_rmse, test_rmse])\n",
    "metrics['R2'].extend([train_r2, test_r2])\n",
    "\n",
    "# Convert metrics to DataFrame\n",
    "metrics_df = pd.DataFrame(metrics)\n",
    "\n",
    "# Display the results\n",
    "print(metrics_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the intercept and coefficients from the best Lasso model\n",
    "lasso_intercept = best_lasso.intercept_\n",
    "lasso_coefficients = best_lasso.coef_\n",
    "\n",
    "# Get the feature names\n",
    "feature_names = X.columns\n",
    "\n",
    "# Create the regression formula\n",
    "regression_formula = f\"y = {lasso_intercept:.4f}\"\n",
    "for coef, name in zip(lasso_coefficients, feature_names):\n",
    "    if coef != 0:  # Include only non-zero coefficients\n",
    "        regression_formula += f\" + ({coef:.4f} * {name})\"\n",
    "\n",
    "print(\"Lasso Regression Formula:\")\n",
    "print(regression_formula)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get feature importances from the best XGBoost model\n",
    "xgb_feature_importances = best_xgb.feature_importances_\n",
    "\n",
    "# Create a DataFrame for feature importances\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': xgb_feature_importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Plot the feature importances\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.barh(feature_importance_df['Feature'], feature_importance_df['Importance'], color='skyblue')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.title('XGBoost Feature Importances')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize the SHAP explainer\n",
    "explainer = shap.Explainer(best_xgb)\n",
    "\n",
    "# Compute SHAP values for the test set\n",
    "shap_values = explainer(X_test)\n",
    "\n",
    "# SHAP summary plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "shap.summary_plot(shap_values, X_test, plot_type=\"bar\")\n",
    "plt.title('Feature Importance with SHAP Values')\n",
    "plt.show()\n",
    "\n",
    "# SHAP summary plot with direction of association\n",
    "plt.figure(figsize=(10, 8))\n",
    "shap.summary_plot(shap_values, X_test)\n",
    "plt.title('SHAP Summary Plot')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
